{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp overfit on the moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=2, save_best_only=True)\n",
    "\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 70 samples\n",
      "Epoch 1/4000\n",
      " - 0s - loss: 0.7046 - accuracy: 0.4667 - val_loss: 0.6847 - val_accuracy: 0.5143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51429, saving model to best_model.h5\n",
      "Epoch 2/4000\n",
      " - 0s - loss: 0.6876 - accuracy: 0.4667 - val_loss: 0.6737 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.51429 to 0.64286, saving model to best_model.h5\n",
      "Epoch 3/4000\n",
      " - 0s - loss: 0.6712 - accuracy: 0.6000 - val_loss: 0.6630 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.64286 to 0.82857, saving model to best_model.h5\n",
      "Epoch 4/4000\n",
      " - 0s - loss: 0.6551 - accuracy: 0.8000 - val_loss: 0.6528 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.82857\n",
      "Epoch 5/4000\n",
      " - 0s - loss: 0.6395 - accuracy: 0.8667 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.82857\n",
      "Epoch 6/4000\n",
      " - 0s - loss: 0.6244 - accuracy: 0.8667 - val_loss: 0.6333 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.82857\n",
      "Epoch 7/4000\n",
      " - 0s - loss: 0.6098 - accuracy: 0.8667 - val_loss: 0.6241 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.82857\n",
      "Epoch 8/4000\n",
      " - 0s - loss: 0.5956 - accuracy: 0.8667 - val_loss: 0.6152 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82857\n",
      "Epoch 9/4000\n",
      " - 0s - loss: 0.5818 - accuracy: 0.9000 - val_loss: 0.6067 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82857\n",
      "Epoch 10/4000\n",
      " - 0s - loss: 0.5685 - accuracy: 0.9000 - val_loss: 0.5986 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82857\n",
      "Epoch 11/4000\n",
      " - 0s - loss: 0.5556 - accuracy: 0.9000 - val_loss: 0.5907 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82857\n",
      "Epoch 12/4000\n",
      " - 0s - loss: 0.5431 - accuracy: 0.9000 - val_loss: 0.5831 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82857\n",
      "Epoch 13/4000\n",
      " - 0s - loss: 0.5309 - accuracy: 0.9000 - val_loss: 0.5759 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82857\n",
      "Epoch 14/4000\n",
      " - 0s - loss: 0.5190 - accuracy: 0.9000 - val_loss: 0.5689 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82857\n",
      "Epoch 15/4000\n",
      " - 0s - loss: 0.5075 - accuracy: 0.9000 - val_loss: 0.5621 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82857\n",
      "Epoch 16/4000\n",
      " - 0s - loss: 0.4963 - accuracy: 0.9000 - val_loss: 0.5556 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82857\n",
      "Epoch 17/4000\n",
      " - 0s - loss: 0.4854 - accuracy: 0.9000 - val_loss: 0.5494 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82857\n",
      "Epoch 18/4000\n",
      " - 0s - loss: 0.4748 - accuracy: 0.9000 - val_loss: 0.5435 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82857\n",
      "Epoch 19/4000\n",
      " - 0s - loss: 0.4646 - accuracy: 0.9000 - val_loss: 0.5378 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82857\n",
      "Epoch 20/4000\n",
      " - 0s - loss: 0.4547 - accuracy: 0.9000 - val_loss: 0.5324 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82857\n",
      "Epoch 21/4000\n",
      " - 0s - loss: 0.4451 - accuracy: 0.9333 - val_loss: 0.5272 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.82857\n",
      "Epoch 22/4000\n",
      " - 0s - loss: 0.4357 - accuracy: 0.9333 - val_loss: 0.5223 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82857\n",
      "Epoch 23/4000\n",
      " - 0s - loss: 0.4266 - accuracy: 0.8667 - val_loss: 0.5175 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82857\n",
      "Epoch 24/4000\n",
      " - 0s - loss: 0.4177 - accuracy: 0.8667 - val_loss: 0.5129 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82857\n",
      "Epoch 25/4000\n",
      " - 0s - loss: 0.4092 - accuracy: 0.8667 - val_loss: 0.5086 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82857\n",
      "Epoch 26/4000\n",
      " - 0s - loss: 0.4009 - accuracy: 0.8667 - val_loss: 0.5045 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82857\n",
      "Epoch 27/4000\n",
      " - 0s - loss: 0.3929 - accuracy: 0.8667 - val_loss: 0.5006 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82857\n",
      "Epoch 28/4000\n",
      " - 0s - loss: 0.3851 - accuracy: 0.8667 - val_loss: 0.4968 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.82857\n",
      "Epoch 29/4000\n",
      " - 0s - loss: 0.3776 - accuracy: 0.9000 - val_loss: 0.4933 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.82857\n",
      "Epoch 30/4000\n",
      " - 0s - loss: 0.3703 - accuracy: 0.9000 - val_loss: 0.4899 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.82857\n",
      "Epoch 31/4000\n",
      " - 0s - loss: 0.3632 - accuracy: 0.9000 - val_loss: 0.4867 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.82857\n",
      "Epoch 32/4000\n",
      " - 0s - loss: 0.3564 - accuracy: 0.9000 - val_loss: 0.4837 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.82857\n",
      "Epoch 33/4000\n",
      " - 0s - loss: 0.3498 - accuracy: 0.9000 - val_loss: 0.4809 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.82857\n",
      "Epoch 34/4000\n",
      " - 0s - loss: 0.3433 - accuracy: 0.9000 - val_loss: 0.4781 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.82857\n",
      "Epoch 35/4000\n",
      " - 0s - loss: 0.3371 - accuracy: 0.9000 - val_loss: 0.4756 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.82857\n",
      "Epoch 36/4000\n",
      " - 0s - loss: 0.3311 - accuracy: 0.9000 - val_loss: 0.4732 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.82857\n",
      "Epoch 37/4000\n",
      " - 0s - loss: 0.3253 - accuracy: 0.9000 - val_loss: 0.4710 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.82857\n",
      "Epoch 38/4000\n",
      " - 0s - loss: 0.3198 - accuracy: 0.9000 - val_loss: 0.4689 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.82857\n",
      "Epoch 39/4000\n",
      " - 0s - loss: 0.3144 - accuracy: 0.9000 - val_loss: 0.4670 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.82857\n",
      "Epoch 40/4000\n",
      " - 0s - loss: 0.3092 - accuracy: 0.9000 - val_loss: 0.4652 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.82857\n",
      "Epoch 41/4000\n",
      " - 0s - loss: 0.3042 - accuracy: 0.9000 - val_loss: 0.4635 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.82857\n",
      "Epoch 42/4000\n",
      " - 0s - loss: 0.2994 - accuracy: 0.9000 - val_loss: 0.4619 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.82857\n",
      "Epoch 43/4000\n",
      " - 0s - loss: 0.2948 - accuracy: 0.9000 - val_loss: 0.4604 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.82857\n",
      "Epoch 44/4000\n",
      " - 0s - loss: 0.2904 - accuracy: 0.9000 - val_loss: 0.4591 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.82857\n",
      "Epoch 45/4000\n",
      " - 0s - loss: 0.2861 - accuracy: 0.9000 - val_loss: 0.4578 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.82857\n",
      "Epoch 46/4000\n",
      " - 0s - loss: 0.2820 - accuracy: 0.9000 - val_loss: 0.4566 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.82857\n",
      "Epoch 47/4000\n",
      " - 0s - loss: 0.2781 - accuracy: 0.9000 - val_loss: 0.4556 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.82857\n",
      "Epoch 48/4000\n",
      " - 0s - loss: 0.2743 - accuracy: 0.9000 - val_loss: 0.4546 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.82857\n",
      "Epoch 49/4000\n",
      " - 0s - loss: 0.2707 - accuracy: 0.9000 - val_loss: 0.4536 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.82857\n",
      "Epoch 50/4000\n",
      " - 0s - loss: 0.2672 - accuracy: 0.9000 - val_loss: 0.4528 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.82857\n",
      "Epoch 51/4000\n",
      " - 0s - loss: 0.2638 - accuracy: 0.9000 - val_loss: 0.4520 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.82857\n",
      "Epoch 52/4000\n",
      " - 0s - loss: 0.2606 - accuracy: 0.9000 - val_loss: 0.4512 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.82857\n",
      "Epoch 53/4000\n",
      " - 0s - loss: 0.2575 - accuracy: 0.9000 - val_loss: 0.4505 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.82857\n",
      "Epoch 54/4000\n",
      " - 0s - loss: 0.2545 - accuracy: 0.9000 - val_loss: 0.4499 - val_accuracy: 0.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.82857\n",
      "Epoch 55/4000\n",
      " - 0s - loss: 0.2516 - accuracy: 0.9000 - val_loss: 0.4493 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.82857\n",
      "Epoch 56/4000\n",
      " - 0s - loss: 0.2488 - accuracy: 0.9000 - val_loss: 0.4487 - val_accuracy: 0.7286\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.82857\n",
      "Epoch 57/4000\n",
      " - 0s - loss: 0.2462 - accuracy: 0.9000 - val_loss: 0.4482 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.82857\n",
      "Epoch 58/4000\n",
      " - 0s - loss: 0.2436 - accuracy: 0.9000 - val_loss: 0.4477 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.82857\n",
      "Epoch 59/4000\n",
      " - 0s - loss: 0.2412 - accuracy: 0.9000 - val_loss: 0.4472 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.82857\n",
      "Epoch 60/4000\n",
      " - 0s - loss: 0.2388 - accuracy: 0.9000 - val_loss: 0.4468 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.82857\n",
      "Epoch 61/4000\n",
      " - 0s - loss: 0.2365 - accuracy: 0.9000 - val_loss: 0.4464 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.82857\n",
      "Epoch 62/4000\n",
      " - 0s - loss: 0.2344 - accuracy: 0.9000 - val_loss: 0.4460 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.82857\n",
      "Epoch 63/4000\n",
      " - 0s - loss: 0.2323 - accuracy: 0.9000 - val_loss: 0.4456 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.82857\n",
      "Epoch 64/4000\n",
      " - 0s - loss: 0.2303 - accuracy: 0.9000 - val_loss: 0.4452 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.82857\n",
      "Epoch 65/4000\n",
      " - 0s - loss: 0.2284 - accuracy: 0.9000 - val_loss: 0.4449 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.82857\n",
      "Epoch 66/4000\n",
      " - 0s - loss: 0.2265 - accuracy: 0.9000 - val_loss: 0.4445 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.82857\n",
      "Epoch 67/4000\n",
      " - 0s - loss: 0.2247 - accuracy: 0.9000 - val_loss: 0.4442 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.82857\n",
      "Epoch 68/4000\n",
      " - 0s - loss: 0.2230 - accuracy: 0.9000 - val_loss: 0.4439 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.82857\n",
      "Epoch 69/4000\n",
      " - 0s - loss: 0.2213 - accuracy: 0.9000 - val_loss: 0.4435 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.82857\n",
      "Epoch 70/4000\n",
      " - 0s - loss: 0.2197 - accuracy: 0.9000 - val_loss: 0.4432 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.82857\n",
      "Epoch 71/4000\n",
      " - 0s - loss: 0.2182 - accuracy: 0.9000 - val_loss: 0.4429 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.82857\n",
      "Epoch 72/4000\n",
      " - 0s - loss: 0.2167 - accuracy: 0.9000 - val_loss: 0.4425 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.82857\n",
      "Epoch 73/4000\n",
      " - 0s - loss: 0.2153 - accuracy: 0.9000 - val_loss: 0.4422 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.82857\n",
      "Epoch 74/4000\n",
      " - 0s - loss: 0.2139 - accuracy: 0.9000 - val_loss: 0.4418 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.82857\n",
      "Epoch 75/4000\n",
      " - 0s - loss: 0.2125 - accuracy: 0.9000 - val_loss: 0.4415 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.82857\n",
      "Epoch 76/4000\n",
      " - 0s - loss: 0.2112 - accuracy: 0.9000 - val_loss: 0.4411 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.82857\n",
      "Epoch 77/4000\n",
      " - 0s - loss: 0.2100 - accuracy: 0.9000 - val_loss: 0.4408 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.82857\n",
      "Epoch 78/4000\n",
      " - 0s - loss: 0.2088 - accuracy: 0.9000 - val_loss: 0.4404 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.82857\n",
      "Epoch 79/4000\n",
      " - 0s - loss: 0.2076 - accuracy: 0.9000 - val_loss: 0.4401 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.82857\n",
      "Epoch 80/4000\n",
      " - 0s - loss: 0.2065 - accuracy: 0.9000 - val_loss: 0.4397 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.82857\n",
      "Epoch 81/4000\n",
      " - 0s - loss: 0.2054 - accuracy: 0.9000 - val_loss: 0.4393 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.82857\n",
      "Epoch 82/4000\n",
      " - 0s - loss: 0.2043 - accuracy: 0.9000 - val_loss: 0.4389 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.82857\n",
      "Epoch 83/4000\n",
      " - 0s - loss: 0.2032 - accuracy: 0.9000 - val_loss: 0.4384 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.82857\n",
      "Epoch 84/4000\n",
      " - 0s - loss: 0.2022 - accuracy: 0.9000 - val_loss: 0.4380 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.82857\n",
      "Epoch 85/4000\n",
      " - 0s - loss: 0.2013 - accuracy: 0.9000 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.82857\n",
      "Epoch 86/4000\n",
      " - 0s - loss: 0.2003 - accuracy: 0.9000 - val_loss: 0.4370 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.82857\n",
      "Epoch 87/4000\n",
      " - 0s - loss: 0.1994 - accuracy: 0.9000 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.82857\n",
      "Epoch 88/4000\n",
      " - 0s - loss: 0.1984 - accuracy: 0.9000 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.82857\n",
      "Epoch 89/4000\n",
      " - 0s - loss: 0.1976 - accuracy: 0.9000 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.82857\n",
      "Epoch 90/4000\n",
      " - 0s - loss: 0.1967 - accuracy: 0.9000 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.82857\n",
      "Epoch 91/4000\n",
      " - 0s - loss: 0.1958 - accuracy: 0.9000 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.82857\n",
      "Epoch 92/4000\n",
      " - 0s - loss: 0.1950 - accuracy: 0.9000 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.82857\n",
      "Epoch 93/4000\n",
      " - 0s - loss: 0.1941 - accuracy: 0.9000 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.82857\n",
      "Epoch 94/4000\n",
      " - 0s - loss: 0.1933 - accuracy: 0.9000 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.82857\n",
      "Epoch 95/4000\n",
      " - 0s - loss: 0.1925 - accuracy: 0.9000 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.82857\n",
      "Epoch 96/4000\n",
      " - 0s - loss: 0.1918 - accuracy: 0.9000 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.82857\n",
      "Epoch 97/4000\n",
      " - 0s - loss: 0.1910 - accuracy: 0.9000 - val_loss: 0.4306 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.82857\n",
      "Epoch 98/4000\n",
      " - 0s - loss: 0.1902 - accuracy: 0.9000 - val_loss: 0.4299 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.82857\n",
      "Epoch 99/4000\n",
      " - 0s - loss: 0.1895 - accuracy: 0.9000 - val_loss: 0.4292 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.82857\n",
      "Epoch 100/4000\n",
      " - 0s - loss: 0.1888 - accuracy: 0.9000 - val_loss: 0.4286 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.82857\n",
      "Epoch 101/4000\n",
      " - 0s - loss: 0.1880 - accuracy: 0.9000 - val_loss: 0.4279 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.82857\n",
      "Epoch 102/4000\n",
      " - 0s - loss: 0.1873 - accuracy: 0.9000 - val_loss: 0.4272 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.82857\n",
      "Epoch 103/4000\n",
      " - 0s - loss: 0.1866 - accuracy: 0.9000 - val_loss: 0.4264 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.82857\n",
      "Epoch 104/4000\n",
      " - 0s - loss: 0.1859 - accuracy: 0.9000 - val_loss: 0.4257 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.82857\n",
      "Epoch 105/4000\n",
      " - 0s - loss: 0.1852 - accuracy: 0.9000 - val_loss: 0.4250 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.82857\n",
      "Epoch 106/4000\n",
      " - 0s - loss: 0.1846 - accuracy: 0.9000 - val_loss: 0.4243 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.82857\n",
      "Epoch 107/4000\n",
      " - 0s - loss: 0.1839 - accuracy: 0.9000 - val_loss: 0.4236 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.82857\n",
      "Epoch 108/4000\n",
      " - 0s - loss: 0.1832 - accuracy: 0.9000 - val_loss: 0.4228 - val_accuracy: 0.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.82857\n",
      "Epoch 109/4000\n",
      " - 0s - loss: 0.1826 - accuracy: 0.9000 - val_loss: 0.4221 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.82857\n",
      "Epoch 110/4000\n",
      " - 0s - loss: 0.1819 - accuracy: 0.9000 - val_loss: 0.4214 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.82857\n",
      "Epoch 111/4000\n",
      " - 0s - loss: 0.1813 - accuracy: 0.9000 - val_loss: 0.4206 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.82857\n",
      "Epoch 112/4000\n",
      " - 0s - loss: 0.1807 - accuracy: 0.9000 - val_loss: 0.4199 - val_accuracy: 0.7571\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.82857\n",
      "Epoch 113/4000\n",
      " - 0s - loss: 0.1800 - accuracy: 0.9000 - val_loss: 0.4191 - val_accuracy: 0.7571\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.82857\n",
      "Epoch 114/4000\n",
      " - 0s - loss: 0.1794 - accuracy: 0.9000 - val_loss: 0.4184 - val_accuracy: 0.7571\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.82857\n",
      "Epoch 115/4000\n",
      " - 0s - loss: 0.1788 - accuracy: 0.9000 - val_loss: 0.4176 - val_accuracy: 0.7571\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.82857\n",
      "Epoch 116/4000\n",
      " - 0s - loss: 0.1782 - accuracy: 0.9000 - val_loss: 0.4169 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.82857\n",
      "Epoch 117/4000\n",
      " - 0s - loss: 0.1776 - accuracy: 0.9333 - val_loss: 0.4162 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.82857\n",
      "Epoch 118/4000\n",
      " - 0s - loss: 0.1770 - accuracy: 0.9333 - val_loss: 0.4154 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.82857\n",
      "Epoch 119/4000\n",
      " - 0s - loss: 0.1764 - accuracy: 0.9333 - val_loss: 0.4147 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.82857\n",
      "Epoch 120/4000\n",
      " - 0s - loss: 0.1758 - accuracy: 0.9333 - val_loss: 0.4139 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.82857\n",
      "Epoch 121/4000\n",
      " - 0s - loss: 0.1753 - accuracy: 0.9333 - val_loss: 0.4131 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.82857\n",
      "Epoch 122/4000\n",
      " - 0s - loss: 0.1747 - accuracy: 0.9333 - val_loss: 0.4124 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.82857\n",
      "Epoch 123/4000\n",
      " - 0s - loss: 0.1741 - accuracy: 0.9333 - val_loss: 0.4116 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.82857\n",
      "Epoch 124/4000\n",
      " - 0s - loss: 0.1736 - accuracy: 0.9333 - val_loss: 0.4109 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.82857\n",
      "Epoch 125/4000\n",
      " - 0s - loss: 0.1730 - accuracy: 0.9333 - val_loss: 0.4101 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.82857\n",
      "Epoch 126/4000\n",
      " - 0s - loss: 0.1725 - accuracy: 0.9333 - val_loss: 0.4093 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.82857\n",
      "Epoch 127/4000\n",
      " - 0s - loss: 0.1719 - accuracy: 0.9333 - val_loss: 0.4086 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.82857\n",
      "Epoch 128/4000\n",
      " - 0s - loss: 0.1714 - accuracy: 0.9333 - val_loss: 0.4078 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.82857\n",
      "Epoch 129/4000\n",
      " - 0s - loss: 0.1709 - accuracy: 0.9333 - val_loss: 0.4071 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.82857\n",
      "Epoch 130/4000\n",
      " - 0s - loss: 0.1703 - accuracy: 0.9333 - val_loss: 0.4063 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.82857\n",
      "Epoch 131/4000\n",
      " - 0s - loss: 0.1698 - accuracy: 0.9333 - val_loss: 0.4056 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.82857\n",
      "Epoch 132/4000\n",
      " - 0s - loss: 0.1693 - accuracy: 0.9333 - val_loss: 0.4048 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.82857\n",
      "Epoch 133/4000\n",
      " - 0s - loss: 0.1688 - accuracy: 0.9333 - val_loss: 0.4041 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.82857\n",
      "Epoch 134/4000\n",
      " - 0s - loss: 0.1683 - accuracy: 0.9333 - val_loss: 0.4034 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.82857\n",
      "Epoch 135/4000\n",
      " - 0s - loss: 0.1678 - accuracy: 0.9333 - val_loss: 0.4026 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.82857\n",
      "Epoch 136/4000\n",
      " - 0s - loss: 0.1673 - accuracy: 0.9667 - val_loss: 0.4019 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.82857\n",
      "Epoch 137/4000\n",
      " - 0s - loss: 0.1668 - accuracy: 0.9667 - val_loss: 0.4012 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.82857\n",
      "Epoch 138/4000\n",
      " - 0s - loss: 0.1663 - accuracy: 0.9667 - val_loss: 0.4004 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.82857\n",
      "Epoch 139/4000\n",
      " - 0s - loss: 0.1659 - accuracy: 0.9667 - val_loss: 0.3997 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.82857\n",
      "Epoch 140/4000\n",
      " - 0s - loss: 0.1654 - accuracy: 0.9667 - val_loss: 0.3990 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.82857\n",
      "Epoch 141/4000\n",
      " - 0s - loss: 0.1649 - accuracy: 0.9667 - val_loss: 0.3983 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.82857\n",
      "Epoch 142/4000\n",
      " - 0s - loss: 0.1645 - accuracy: 0.9667 - val_loss: 0.3975 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.82857\n",
      "Epoch 143/4000\n",
      " - 0s - loss: 0.1640 - accuracy: 0.9667 - val_loss: 0.3968 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.82857\n",
      "Epoch 144/4000\n",
      " - 0s - loss: 0.1636 - accuracy: 0.9667 - val_loss: 0.3961 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.82857\n",
      "Epoch 145/4000\n",
      " - 0s - loss: 0.1631 - accuracy: 0.9667 - val_loss: 0.3954 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.82857\n",
      "Epoch 146/4000\n",
      " - 0s - loss: 0.1627 - accuracy: 0.9667 - val_loss: 0.3947 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.82857\n",
      "Epoch 147/4000\n",
      " - 0s - loss: 0.1622 - accuracy: 0.9667 - val_loss: 0.3940 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.82857\n",
      "Epoch 148/4000\n",
      " - 0s - loss: 0.1618 - accuracy: 0.9667 - val_loss: 0.3934 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.82857\n",
      "Epoch 149/4000\n",
      " - 0s - loss: 0.1614 - accuracy: 0.9667 - val_loss: 0.3927 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.82857\n",
      "Epoch 150/4000\n",
      " - 0s - loss: 0.1610 - accuracy: 0.9667 - val_loss: 0.3920 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.82857\n",
      "Epoch 151/4000\n",
      " - 0s - loss: 0.1605 - accuracy: 0.9667 - val_loss: 0.3914 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.82857\n",
      "Epoch 152/4000\n",
      " - 0s - loss: 0.1601 - accuracy: 0.9667 - val_loss: 0.3907 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.82857\n",
      "Epoch 153/4000\n",
      " - 0s - loss: 0.1597 - accuracy: 0.9667 - val_loss: 0.3901 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.82857\n",
      "Epoch 154/4000\n",
      " - 0s - loss: 0.1593 - accuracy: 0.9667 - val_loss: 0.3894 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.82857\n",
      "Epoch 155/4000\n",
      " - 0s - loss: 0.1589 - accuracy: 0.9667 - val_loss: 0.3888 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.82857\n",
      "Epoch 156/4000\n",
      " - 0s - loss: 0.1585 - accuracy: 0.9667 - val_loss: 0.3883 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.82857\n",
      "Epoch 157/4000\n",
      " - 0s - loss: 0.1581 - accuracy: 0.9667 - val_loss: 0.3877 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.82857\n",
      "Epoch 158/4000\n",
      " - 0s - loss: 0.1578 - accuracy: 0.9667 - val_loss: 0.3871 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.82857\n",
      "Epoch 159/4000\n",
      " - 0s - loss: 0.1574 - accuracy: 0.9667 - val_loss: 0.3865 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.82857\n",
      "Epoch 160/4000\n",
      " - 0s - loss: 0.1570 - accuracy: 0.9667 - val_loss: 0.3860 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.82857\n",
      "Epoch 161/4000\n",
      " - 0s - loss: 0.1566 - accuracy: 0.9667 - val_loss: 0.3855 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.82857\n",
      "Epoch 162/4000\n",
      " - 0s - loss: 0.1563 - accuracy: 0.9667 - val_loss: 0.3850 - val_accuracy: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.82857\n",
      "Epoch 163/4000\n",
      " - 0s - loss: 0.1559 - accuracy: 0.9667 - val_loss: 0.3844 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.82857\n",
      "Epoch 164/4000\n",
      " - 0s - loss: 0.1555 - accuracy: 0.9667 - val_loss: 0.3840 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.82857\n",
      "Epoch 165/4000\n",
      " - 0s - loss: 0.1552 - accuracy: 0.9667 - val_loss: 0.3835 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.82857\n",
      "Epoch 166/4000\n",
      " - 0s - loss: 0.1548 - accuracy: 0.9667 - val_loss: 0.3830 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.82857\n",
      "Epoch 167/4000\n",
      " - 0s - loss: 0.1545 - accuracy: 0.9667 - val_loss: 0.3825 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.82857\n",
      "Epoch 168/4000\n",
      " - 0s - loss: 0.1542 - accuracy: 0.9667 - val_loss: 0.3821 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.82857\n",
      "Epoch 169/4000\n",
      " - 0s - loss: 0.1538 - accuracy: 0.9667 - val_loss: 0.3817 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.82857\n",
      "Epoch 170/4000\n",
      " - 0s - loss: 0.1535 - accuracy: 0.9667 - val_loss: 0.3812 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.82857\n",
      "Epoch 171/4000\n",
      " - 0s - loss: 0.1532 - accuracy: 0.9667 - val_loss: 0.3808 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.82857\n",
      "Epoch 172/4000\n",
      " - 0s - loss: 0.1528 - accuracy: 0.9667 - val_loss: 0.3804 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.82857\n",
      "Epoch 173/4000\n",
      " - 0s - loss: 0.1525 - accuracy: 0.9667 - val_loss: 0.3801 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.82857\n",
      "Epoch 174/4000\n",
      " - 0s - loss: 0.1522 - accuracy: 0.9667 - val_loss: 0.3797 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.82857\n",
      "Epoch 175/4000\n",
      " - 0s - loss: 0.1519 - accuracy: 0.9667 - val_loss: 0.3793 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.82857\n",
      "Epoch 176/4000\n",
      " - 0s - loss: 0.1516 - accuracy: 0.9667 - val_loss: 0.3789 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.82857\n",
      "Epoch 177/4000\n",
      " - 0s - loss: 0.1513 - accuracy: 0.9667 - val_loss: 0.3786 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.82857\n",
      "Epoch 178/4000\n",
      " - 0s - loss: 0.1510 - accuracy: 0.9667 - val_loss: 0.3782 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.82857\n",
      "Epoch 179/4000\n",
      " - 0s - loss: 0.1507 - accuracy: 0.9667 - val_loss: 0.3779 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.82857\n",
      "Epoch 180/4000\n",
      " - 0s - loss: 0.1504 - accuracy: 0.9667 - val_loss: 0.3776 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.82857\n",
      "Epoch 181/4000\n",
      " - 0s - loss: 0.1501 - accuracy: 0.9667 - val_loss: 0.3772 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.82857\n",
      "Epoch 182/4000\n",
      " - 0s - loss: 0.1498 - accuracy: 0.9667 - val_loss: 0.3769 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.82857\n",
      "Epoch 183/4000\n",
      " - 0s - loss: 0.1496 - accuracy: 0.9667 - val_loss: 0.3766 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.82857\n",
      "Epoch 184/4000\n",
      " - 0s - loss: 0.1493 - accuracy: 0.9667 - val_loss: 0.3763 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.82857\n",
      "Epoch 185/4000\n",
      " - 0s - loss: 0.1490 - accuracy: 0.9667 - val_loss: 0.3760 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.82857\n",
      "Epoch 186/4000\n",
      " - 0s - loss: 0.1488 - accuracy: 0.9667 - val_loss: 0.3757 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.82857\n",
      "Epoch 187/4000\n",
      " - 0s - loss: 0.1485 - accuracy: 0.9667 - val_loss: 0.3754 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.82857\n",
      "Epoch 188/4000\n",
      " - 0s - loss: 0.1482 - accuracy: 0.9667 - val_loss: 0.3752 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.82857\n",
      "Epoch 189/4000\n",
      " - 0s - loss: 0.1480 - accuracy: 0.9667 - val_loss: 0.3749 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.82857\n",
      "Epoch 190/4000\n",
      " - 0s - loss: 0.1477 - accuracy: 0.9667 - val_loss: 0.3747 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.82857\n",
      "Epoch 191/4000\n",
      " - 0s - loss: 0.1475 - accuracy: 0.9667 - val_loss: 0.3744 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.82857\n",
      "Epoch 192/4000\n",
      " - 0s - loss: 0.1472 - accuracy: 0.9667 - val_loss: 0.3742 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.82857\n",
      "Epoch 193/4000\n",
      " - 0s - loss: 0.1470 - accuracy: 0.9667 - val_loss: 0.3740 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.82857\n",
      "Epoch 194/4000\n",
      " - 0s - loss: 0.1468 - accuracy: 0.9667 - val_loss: 0.3738 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.82857\n",
      "Epoch 195/4000\n",
      " - 0s - loss: 0.1465 - accuracy: 0.9667 - val_loss: 0.3736 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.82857\n",
      "Epoch 196/4000\n",
      " - 0s - loss: 0.1463 - accuracy: 0.9667 - val_loss: 0.3734 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.82857\n",
      "Epoch 197/4000\n",
      " - 0s - loss: 0.1461 - accuracy: 0.9667 - val_loss: 0.3732 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.82857\n",
      "Epoch 198/4000\n",
      " - 0s - loss: 0.1459 - accuracy: 0.9667 - val_loss: 0.3731 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.82857\n",
      "Epoch 199/4000\n",
      " - 0s - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.3729 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.82857\n",
      "Epoch 200/4000\n",
      " - 0s - loss: 0.1454 - accuracy: 0.9667 - val_loss: 0.3727 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.82857\n",
      "Epoch 201/4000\n",
      " - 0s - loss: 0.1452 - accuracy: 0.9667 - val_loss: 0.3726 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.82857\n",
      "Epoch 202/4000\n",
      " - 0s - loss: 0.1450 - accuracy: 0.9667 - val_loss: 0.3725 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.82857\n",
      "Epoch 203/4000\n",
      " - 0s - loss: 0.1448 - accuracy: 0.9667 - val_loss: 0.3724 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.82857\n",
      "Epoch 204/4000\n",
      " - 0s - loss: 0.1446 - accuracy: 0.9667 - val_loss: 0.3722 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.82857\n",
      "Epoch 205/4000\n",
      " - 0s - loss: 0.1444 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.82857\n",
      "Epoch 206/4000\n",
      " - 0s - loss: 0.1443 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.82857\n",
      "Epoch 207/4000\n",
      " - 0s - loss: 0.1441 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.82857\n",
      "Epoch 208/4000\n",
      " - 0s - loss: 0.1439 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.82857\n",
      "Epoch 209/4000\n",
      " - 0s - loss: 0.1437 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.82857\n",
      "Epoch 210/4000\n",
      " - 0s - loss: 0.1435 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.82857\n",
      "Epoch 211/4000\n",
      " - 0s - loss: 0.1434 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.82857\n",
      "Epoch 212/4000\n",
      " - 0s - loss: 0.1432 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.82857\n",
      "Epoch 213/4000\n",
      " - 0s - loss: 0.1430 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.82857\n",
      "Epoch 214/4000\n",
      " - 0s - loss: 0.1429 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.82857\n",
      "Epoch 215/4000\n",
      " - 0s - loss: 0.1427 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.82857\n",
      "Epoch 216/4000\n",
      " - 0s - loss: 0.1425 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.82857\n",
      "Epoch 217/4000\n",
      " - 0s - loss: 0.1424 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.82857\n",
      "Epoch 218/4000\n",
      " - 0s - loss: 0.1422 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.82857\n",
      "Epoch 219/4000\n",
      " - 0s - loss: 0.1421 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.82857\n",
      "Epoch 220/4000\n",
      " - 0s - loss: 0.1419 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.82857\n",
      "Epoch 221/4000\n",
      " - 0s - loss: 0.1418 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.82857\n",
      "Epoch 222/4000\n",
      " - 0s - loss: 0.1416 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.82857\n",
      "Epoch 223/4000\n",
      " - 0s - loss: 0.1415 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.82857\n",
      "Epoch 224/4000\n",
      " - 0s - loss: 0.1413 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.82857\n",
      "Epoch 225/4000\n",
      " - 0s - loss: 0.1412 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.82857\n",
      "Epoch 226/4000\n",
      " - 0s - loss: 0.1410 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.82857\n",
      "Epoch 227/4000\n",
      " - 0s - loss: 0.1409 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.82857\n",
      "Epoch 228/4000\n",
      " - 0s - loss: 0.1408 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.82857\n",
      "Epoch 229/4000\n",
      " - 0s - loss: 0.1406 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.82857\n",
      "Epoch 230/4000\n",
      " - 0s - loss: 0.1405 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.82857\n",
      "Epoch 231/4000\n",
      " - 0s - loss: 0.1404 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.82857\n",
      "Epoch 232/4000\n",
      " - 0s - loss: 0.1402 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.82857\n",
      "Epoch 233/4000\n",
      " - 0s - loss: 0.1401 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.82857\n",
      "Epoch 234/4000\n",
      " - 0s - loss: 0.1400 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.82857\n",
      "Epoch 235/4000\n",
      " - 0s - loss: 0.1398 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.82857\n",
      "Epoch 236/4000\n",
      " - 0s - loss: 0.1397 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.82857\n",
      "Epoch 237/4000\n",
      " - 0s - loss: 0.1396 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.82857\n",
      "Epoch 238/4000\n",
      " - 0s - loss: 0.1395 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.82857\n",
      "Epoch 239/4000\n",
      " - 0s - loss: 0.1393 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.82857\n",
      "Epoch 240/4000\n",
      " - 0s - loss: 0.1392 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.82857\n",
      "Epoch 241/4000\n",
      " - 0s - loss: 0.1391 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.82857\n",
      "Epoch 242/4000\n",
      " - 0s - loss: 0.1389 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.82857\n",
      "Epoch 243/4000\n",
      " - 0s - loss: 0.1388 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.82857\n",
      "Epoch 244/4000\n",
      " - 0s - loss: 0.1387 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.82857\n",
      "Epoch 245/4000\n",
      " - 0s - loss: 0.1386 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.82857\n",
      "Epoch 246/4000\n",
      " - 0s - loss: 0.1385 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.82857\n",
      "Epoch 247/4000\n",
      " - 0s - loss: 0.1384 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.82857\n",
      "Epoch 248/4000\n",
      " - 0s - loss: 0.1382 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.82857\n",
      "Epoch 249/4000\n",
      " - 0s - loss: 0.1381 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.82857\n",
      "Epoch 250/4000\n",
      " - 0s - loss: 0.1380 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.82857\n",
      "Epoch 251/4000\n",
      " - 0s - loss: 0.1379 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.82857\n",
      "Epoch 252/4000\n",
      " - 0s - loss: 0.1378 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.82857\n",
      "Epoch 253/4000\n",
      " - 0s - loss: 0.1377 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.82857\n",
      "Epoch 254/4000\n",
      " - 0s - loss: 0.1376 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.82857\n",
      "Epoch 255/4000\n",
      " - 0s - loss: 0.1374 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.82857\n",
      "Epoch 256/4000\n",
      " - 0s - loss: 0.1373 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.82857\n",
      "Epoch 257/4000\n",
      " - 0s - loss: 0.1372 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.82857\n",
      "Epoch 258/4000\n",
      " - 0s - loss: 0.1371 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.82857\n",
      "Epoch 259/4000\n",
      " - 0s - loss: 0.1370 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.82857\n",
      "Epoch 260/4000\n",
      " - 0s - loss: 0.1369 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.82857\n",
      "Epoch 261/4000\n",
      " - 0s - loss: 0.1368 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.82857\n",
      "Epoch 262/4000\n",
      " - 0s - loss: 0.1367 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.82857\n",
      "Epoch 263/4000\n",
      " - 0s - loss: 0.1366 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.82857\n",
      "Epoch 264/4000\n",
      " - 0s - loss: 0.1365 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.82857\n",
      "Epoch 265/4000\n",
      " - 0s - loss: 0.1364 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.82857\n",
      "Epoch 266/4000\n",
      " - 0s - loss: 0.1363 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.82857\n",
      "Epoch 267/4000\n",
      " - 0s - loss: 0.1361 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.82857\n",
      "Epoch 268/4000\n",
      " - 0s - loss: 0.1360 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.82857\n",
      "Epoch 269/4000\n",
      " - 0s - loss: 0.1359 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.82857\n",
      "Epoch 270/4000\n",
      " - 0s - loss: 0.1358 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.82857\n",
      "Epoch 271/4000\n",
      " - 0s - loss: 0.1357 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.82857\n",
      "Epoch 272/4000\n",
      " - 0s - loss: 0.1356 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.82857\n",
      "Epoch 273/4000\n",
      " - 0s - loss: 0.1355 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.82857\n",
      "Epoch 274/4000\n",
      " - 0s - loss: 0.1354 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.82857\n",
      "Epoch 275/4000\n",
      " - 0s - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.82857\n",
      "Epoch 276/4000\n",
      " - 0s - loss: 0.1352 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.82857\n",
      "Epoch 277/4000\n",
      " - 0s - loss: 0.1351 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.82857\n",
      "Epoch 278/4000\n",
      " - 0s - loss: 0.1350 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.82857\n",
      "Epoch 279/4000\n",
      " - 0s - loss: 0.1349 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.82857\n",
      "Epoch 280/4000\n",
      " - 0s - loss: 0.1348 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.82857\n",
      "Epoch 281/4000\n",
      " - 0s - loss: 0.1347 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.82857\n",
      "Epoch 282/4000\n",
      " - 0s - loss: 0.1346 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.82857\n",
      "Epoch 283/4000\n",
      " - 0s - loss: 0.1345 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.82857\n",
      "Epoch 284/4000\n",
      " - 0s - loss: 0.1344 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.82857\n",
      "Epoch 285/4000\n",
      " - 0s - loss: 0.1343 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.82857\n",
      "Epoch 286/4000\n",
      " - 0s - loss: 0.1342 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.82857\n",
      "Epoch 287/4000\n",
      " - 0s - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.82857\n",
      "Epoch 288/4000\n",
      " - 0s - loss: 0.1340 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.82857\n",
      "Epoch 289/4000\n",
      " - 0s - loss: 0.1339 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.82857\n",
      "Epoch 290/4000\n",
      " - 0s - loss: 0.1338 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.82857\n",
      "Epoch 291/4000\n",
      " - 0s - loss: 0.1337 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.82857\n",
      "Epoch 292/4000\n",
      " - 0s - loss: 0.1336 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.82857\n",
      "Epoch 293/4000\n",
      " - 0s - loss: 0.1335 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.82857\n",
      "Epoch 294/4000\n",
      " - 0s - loss: 0.1334 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00294: val_accuracy improved from 0.82857 to 0.84286, saving model to best_model.h5\n",
      "Epoch 295/4000\n",
      " - 0s - loss: 0.1333 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.84286\n",
      "Epoch 296/4000\n",
      " - 0s - loss: 0.1332 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.84286\n",
      "Epoch 297/4000\n",
      " - 0s - loss: 0.1331 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.84286\n",
      "Epoch 298/4000\n",
      " - 0s - loss: 0.1330 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.84286\n",
      "Epoch 299/4000\n",
      " - 0s - loss: 0.1329 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.84286\n",
      "Epoch 300/4000\n",
      " - 0s - loss: 0.1328 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.84286\n",
      "Epoch 301/4000\n",
      " - 0s - loss: 0.1327 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.84286\n",
      "Epoch 302/4000\n",
      " - 0s - loss: 0.1326 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.84286\n",
      "Epoch 303/4000\n",
      " - 0s - loss: 0.1325 - accuracy: 0.9667 - val_loss: 0.3712 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.84286\n",
      "Epoch 304/4000\n",
      " - 0s - loss: 0.1324 - accuracy: 0.9667 - val_loss: 0.3712 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.84286\n",
      "Epoch 305/4000\n",
      " - 0s - loss: 0.1323 - accuracy: 0.9667 - val_loss: 0.3712 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.84286\n",
      "Epoch 306/4000\n",
      " - 0s - loss: 0.1322 - accuracy: 0.9667 - val_loss: 0.3712 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.84286\n",
      "Epoch 307/4000\n",
      " - 0s - loss: 0.1321 - accuracy: 0.9667 - val_loss: 0.3711 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.84286\n",
      "Epoch 308/4000\n",
      " - 0s - loss: 0.1320 - accuracy: 0.9667 - val_loss: 0.3711 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.84286\n",
      "Epoch 309/4000\n",
      " - 0s - loss: 0.1319 - accuracy: 0.9667 - val_loss: 0.3711 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.84286\n",
      "Epoch 310/4000\n",
      " - 0s - loss: 0.1318 - accuracy: 0.9667 - val_loss: 0.3710 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.84286\n",
      "Epoch 311/4000\n",
      " - 0s - loss: 0.1317 - accuracy: 0.9667 - val_loss: 0.3710 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.84286\n",
      "Epoch 312/4000\n",
      " - 0s - loss: 0.1316 - accuracy: 0.9667 - val_loss: 0.3709 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.84286\n",
      "Epoch 313/4000\n",
      " - 0s - loss: 0.1315 - accuracy: 0.9667 - val_loss: 0.3708 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.84286\n",
      "Epoch 314/4000\n",
      " - 0s - loss: 0.1313 - accuracy: 0.9667 - val_loss: 0.3708 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.84286\n",
      "Epoch 315/4000\n",
      " - 0s - loss: 0.1312 - accuracy: 0.9667 - val_loss: 0.3707 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.84286\n",
      "Epoch 316/4000\n",
      " - 0s - loss: 0.1311 - accuracy: 0.9667 - val_loss: 0.3707 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.84286\n",
      "Epoch 317/4000\n",
      " - 0s - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.3707 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.84286\n",
      "Epoch 318/4000\n",
      " - 0s - loss: 0.1309 - accuracy: 0.9667 - val_loss: 0.3706 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.84286\n",
      "Epoch 319/4000\n",
      " - 0s - loss: 0.1308 - accuracy: 0.9667 - val_loss: 0.3705 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.84286\n",
      "Epoch 320/4000\n",
      " - 0s - loss: 0.1307 - accuracy: 0.9667 - val_loss: 0.3704 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.84286\n",
      "Epoch 321/4000\n",
      " - 0s - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.3703 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.84286\n",
      "Epoch 322/4000\n",
      " - 0s - loss: 0.1305 - accuracy: 0.9667 - val_loss: 0.3703 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.84286\n",
      "Epoch 323/4000\n",
      " - 0s - loss: 0.1304 - accuracy: 0.9667 - val_loss: 0.3702 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.84286\n",
      "Epoch 324/4000\n",
      " - 0s - loss: 0.1303 - accuracy: 0.9667 - val_loss: 0.3702 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.84286\n",
      "Epoch 325/4000\n",
      " - 0s - loss: 0.1302 - accuracy: 0.9667 - val_loss: 0.3702 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.84286\n",
      "Epoch 326/4000\n",
      " - 0s - loss: 0.1301 - accuracy: 0.9667 - val_loss: 0.3701 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.84286\n",
      "Epoch 327/4000\n",
      " - 0s - loss: 0.1300 - accuracy: 0.9667 - val_loss: 0.3701 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.84286\n",
      "Epoch 328/4000\n",
      " - 0s - loss: 0.1299 - accuracy: 0.9667 - val_loss: 0.3700 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.84286\n",
      "Epoch 329/4000\n",
      " - 0s - loss: 0.1298 - accuracy: 0.9667 - val_loss: 0.3699 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.84286\n",
      "Epoch 330/4000\n",
      " - 0s - loss: 0.1296 - accuracy: 0.9667 - val_loss: 0.3698 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.84286\n",
      "Epoch 331/4000\n",
      " - 0s - loss: 0.1295 - accuracy: 0.9667 - val_loss: 0.3698 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.84286\n",
      "Epoch 332/4000\n",
      " - 0s - loss: 0.1294 - accuracy: 0.9667 - val_loss: 0.3697 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.84286\n",
      "Epoch 333/4000\n",
      " - 0s - loss: 0.1293 - accuracy: 0.9667 - val_loss: 0.3697 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.84286\n",
      "Epoch 334/4000\n",
      " - 0s - loss: 0.1292 - accuracy: 0.9667 - val_loss: 0.3696 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.84286\n",
      "Epoch 335/4000\n",
      " - 0s - loss: 0.1291 - accuracy: 0.9667 - val_loss: 0.3695 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.84286\n",
      "Epoch 336/4000\n",
      " - 0s - loss: 0.1290 - accuracy: 0.9667 - val_loss: 0.3694 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.84286\n",
      "Epoch 337/4000\n",
      " - 0s - loss: 0.1289 - accuracy: 0.9667 - val_loss: 0.3693 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.84286\n",
      "Epoch 338/4000\n",
      " - 0s - loss: 0.1288 - accuracy: 0.9667 - val_loss: 0.3692 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.84286\n",
      "Epoch 339/4000\n",
      " - 0s - loss: 0.1287 - accuracy: 0.9667 - val_loss: 0.3691 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.84286\n",
      "Epoch 340/4000\n",
      " - 0s - loss: 0.1285 - accuracy: 0.9667 - val_loss: 0.3690 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.84286\n",
      "Epoch 341/4000\n",
      " - 0s - loss: 0.1284 - accuracy: 0.9667 - val_loss: 0.3688 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.84286\n",
      "Epoch 342/4000\n",
      " - 0s - loss: 0.1283 - accuracy: 0.9667 - val_loss: 0.3687 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.84286\n",
      "Epoch 343/4000\n",
      " - 0s - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.3686 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.84286\n",
      "Epoch 344/4000\n",
      " - 0s - loss: 0.1281 - accuracy: 0.9667 - val_loss: 0.3685 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.84286\n",
      "Epoch 345/4000\n",
      " - 0s - loss: 0.1280 - accuracy: 0.9667 - val_loss: 0.3685 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.84286\n",
      "Epoch 346/4000\n",
      " - 0s - loss: 0.1279 - accuracy: 0.9667 - val_loss: 0.3684 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.84286\n",
      "Epoch 347/4000\n",
      " - 0s - loss: 0.1278 - accuracy: 0.9667 - val_loss: 0.3683 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.84286\n",
      "Epoch 348/4000\n",
      " - 0s - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.3681 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.84286\n",
      "Epoch 349/4000\n",
      " - 0s - loss: 0.1275 - accuracy: 0.9667 - val_loss: 0.3679 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.84286\n",
      "Epoch 350/4000\n",
      " - 0s - loss: 0.1274 - accuracy: 0.9667 - val_loss: 0.3677 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.84286\n",
      "Epoch 351/4000\n",
      " - 0s - loss: 0.1273 - accuracy: 0.9667 - val_loss: 0.3676 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.84286\n",
      "Epoch 352/4000\n",
      " - 0s - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.3675 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.84286\n",
      "Epoch 353/4000\n",
      " - 0s - loss: 0.1270 - accuracy: 0.9667 - val_loss: 0.3675 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.84286\n",
      "Epoch 354/4000\n",
      " - 0s - loss: 0.1269 - accuracy: 0.9667 - val_loss: 0.3673 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.84286\n",
      "Epoch 355/4000\n",
      " - 0s - loss: 0.1268 - accuracy: 0.9667 - val_loss: 0.3671 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.84286\n",
      "Epoch 356/4000\n",
      " - 0s - loss: 0.1267 - accuracy: 0.9667 - val_loss: 0.3669 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.84286\n",
      "Epoch 357/4000\n",
      " - 0s - loss: 0.1266 - accuracy: 0.9667 - val_loss: 0.3667 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.84286\n",
      "Epoch 358/4000\n",
      " - 0s - loss: 0.1264 - accuracy: 0.9667 - val_loss: 0.3665 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.84286\n",
      "Epoch 359/4000\n",
      " - 0s - loss: 0.1263 - accuracy: 0.9667 - val_loss: 0.3664 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.84286\n",
      "Epoch 360/4000\n",
      " - 0s - loss: 0.1262 - accuracy: 0.9667 - val_loss: 0.3663 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.84286\n",
      "Epoch 361/4000\n",
      " - 0s - loss: 0.1261 - accuracy: 0.9667 - val_loss: 0.3663 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.84286\n",
      "Epoch 362/4000\n",
      " - 0s - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.3661 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.84286\n",
      "Epoch 363/4000\n",
      " - 0s - loss: 0.1258 - accuracy: 0.9667 - val_loss: 0.3659 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.84286\n",
      "Epoch 364/4000\n",
      " - 0s - loss: 0.1257 - accuracy: 0.9667 - val_loss: 0.3657 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.84286\n",
      "Epoch 365/4000\n",
      " - 0s - loss: 0.1255 - accuracy: 0.9667 - val_loss: 0.3654 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.84286\n",
      "Epoch 366/4000\n",
      " - 0s - loss: 0.1254 - accuracy: 0.9667 - val_loss: 0.3652 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.84286\n",
      "Epoch 367/4000\n",
      " - 0s - loss: 0.1253 - accuracy: 0.9667 - val_loss: 0.3650 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.84286\n",
      "Epoch 368/4000\n",
      " - 0s - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.3649 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.84286\n",
      "Epoch 369/4000\n",
      " - 0s - loss: 0.1250 - accuracy: 0.9667 - val_loss: 0.3647 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.84286\n",
      "Epoch 370/4000\n",
      " - 0s - loss: 0.1249 - accuracy: 0.9667 - val_loss: 0.3645 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.84286\n",
      "Epoch 371/4000\n",
      " - 0s - loss: 0.1247 - accuracy: 0.9667 - val_loss: 0.3642 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.84286\n",
      "Epoch 372/4000\n",
      " - 0s - loss: 0.1246 - accuracy: 0.9667 - val_loss: 0.3639 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.84286\n",
      "Epoch 373/4000\n",
      " - 0s - loss: 0.1244 - accuracy: 0.9667 - val_loss: 0.3636 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.84286\n",
      "Epoch 374/4000\n",
      " - 0s - loss: 0.1243 - accuracy: 0.9667 - val_loss: 0.3634 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.84286\n",
      "Epoch 375/4000\n",
      " - 0s - loss: 0.1242 - accuracy: 0.9667 - val_loss: 0.3631 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.84286\n",
      "Epoch 376/4000\n",
      " - 0s - loss: 0.1240 - accuracy: 0.9667 - val_loss: 0.3629 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.84286\n",
      "Epoch 377/4000\n",
      " - 0s - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.3627 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.84286\n",
      "Epoch 378/4000\n",
      " - 0s - loss: 0.1237 - accuracy: 0.9667 - val_loss: 0.3625 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.84286\n",
      "Epoch 379/4000\n",
      " - 0s - loss: 0.1236 - accuracy: 0.9667 - val_loss: 0.3623 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.84286\n",
      "Epoch 380/4000\n",
      " - 0s - loss: 0.1234 - accuracy: 0.9667 - val_loss: 0.3621 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.84286\n",
      "Epoch 381/4000\n",
      " - 0s - loss: 0.1233 - accuracy: 0.9667 - val_loss: 0.3618 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.84286\n",
      "Epoch 382/4000\n",
      " - 0s - loss: 0.1231 - accuracy: 0.9667 - val_loss: 0.3616 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.84286\n",
      "Epoch 383/4000\n",
      " - 0s - loss: 0.1230 - accuracy: 0.9667 - val_loss: 0.3612 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.84286\n",
      "Epoch 384/4000\n",
      " - 0s - loss: 0.1228 - accuracy: 0.9667 - val_loss: 0.3609 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.84286\n",
      "Epoch 385/4000\n",
      " - 0s - loss: 0.1227 - accuracy: 0.9667 - val_loss: 0.3606 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.84286\n",
      "Epoch 386/4000\n",
      " - 0s - loss: 0.1225 - accuracy: 0.9667 - val_loss: 0.3604 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.84286\n",
      "Epoch 387/4000\n",
      " - 0s - loss: 0.1224 - accuracy: 0.9667 - val_loss: 0.3601 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.84286\n",
      "Epoch 388/4000\n",
      " - 0s - loss: 0.1222 - accuracy: 0.9667 - val_loss: 0.3599 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.84286\n",
      "Epoch 389/4000\n",
      " - 0s - loss: 0.1220 - accuracy: 0.9667 - val_loss: 0.3596 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.84286\n",
      "Epoch 390/4000\n",
      " - 0s - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.3593 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.84286\n",
      "Epoch 391/4000\n",
      " - 0s - loss: 0.1217 - accuracy: 0.9667 - val_loss: 0.3591 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.84286\n",
      "Epoch 392/4000\n",
      " - 0s - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.3588 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.84286\n",
      "Epoch 393/4000\n",
      " - 0s - loss: 0.1214 - accuracy: 0.9667 - val_loss: 0.3586 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.84286\n",
      "Epoch 394/4000\n",
      " - 0s - loss: 0.1213 - accuracy: 0.9667 - val_loss: 0.3583 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.84286\n",
      "Epoch 395/4000\n",
      " - 0s - loss: 0.1211 - accuracy: 0.9667 - val_loss: 0.3580 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.84286\n",
      "Epoch 396/4000\n",
      " - 0s - loss: 0.1209 - accuracy: 0.9667 - val_loss: 0.3577 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.84286\n",
      "Epoch 397/4000\n",
      " - 0s - loss: 0.1208 - accuracy: 0.9667 - val_loss: 0.3575 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.84286\n",
      "Epoch 398/4000\n",
      " - 0s - loss: 0.1206 - accuracy: 0.9667 - val_loss: 0.3573 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.84286\n",
      "Epoch 399/4000\n",
      " - 0s - loss: 0.1204 - accuracy: 0.9667 - val_loss: 0.3570 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.84286\n",
      "Epoch 400/4000\n",
      " - 0s - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.3567 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.84286\n",
      "Epoch 401/4000\n",
      " - 0s - loss: 0.1201 - accuracy: 0.9667 - val_loss: 0.3564 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.84286\n",
      "Epoch 402/4000\n",
      " - 0s - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.3562 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.84286\n",
      "Epoch 403/4000\n",
      " - 0s - loss: 0.1198 - accuracy: 0.9667 - val_loss: 0.3559 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.84286\n",
      "Epoch 404/4000\n",
      " - 0s - loss: 0.1196 - accuracy: 0.9667 - val_loss: 0.3556 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.84286\n",
      "Epoch 405/4000\n",
      " - 0s - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.3554 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.84286\n",
      "Epoch 406/4000\n",
      " - 0s - loss: 0.1192 - accuracy: 0.9667 - val_loss: 0.3552 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.84286\n",
      "Epoch 407/4000\n",
      " - 0s - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.3550 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.84286\n",
      "Epoch 408/4000\n",
      " - 0s - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.3547 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.84286\n",
      "Epoch 409/4000\n",
      " - 0s - loss: 0.1187 - accuracy: 0.9667 - val_loss: 0.3544 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.84286\n",
      "Epoch 410/4000\n",
      " - 0s - loss: 0.1185 - accuracy: 0.9667 - val_loss: 0.3542 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.84286\n",
      "Epoch 411/4000\n",
      " - 0s - loss: 0.1184 - accuracy: 0.9667 - val_loss: 0.3539 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.84286\n",
      "Epoch 412/4000\n",
      " - 0s - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.3536 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.84286\n",
      "Epoch 413/4000\n",
      " - 0s - loss: 0.1180 - accuracy: 0.9667 - val_loss: 0.3534 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.84286\n",
      "Epoch 414/4000\n",
      " - 0s - loss: 0.1178 - accuracy: 0.9667 - val_loss: 0.3531 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.84286\n",
      "Epoch 415/4000\n",
      " - 0s - loss: 0.1177 - accuracy: 0.9667 - val_loss: 0.3529 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.84286\n",
      "Epoch 416/4000\n",
      " - 0s - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.3528 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.84286\n",
      "Epoch 417/4000\n",
      " - 0s - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.3526 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.84286\n",
      "Epoch 418/4000\n",
      " - 0s - loss: 0.1171 - accuracy: 0.9667 - val_loss: 0.3524 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.84286\n",
      "Epoch 419/4000\n",
      " - 0s - loss: 0.1169 - accuracy: 0.9667 - val_loss: 0.3521 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.84286\n",
      "Epoch 420/4000\n",
      " - 0s - loss: 0.1168 - accuracy: 0.9667 - val_loss: 0.3518 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.84286\n",
      "Epoch 421/4000\n",
      " - 0s - loss: 0.1166 - accuracy: 0.9667 - val_loss: 0.3515 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.84286\n",
      "Epoch 422/4000\n",
      " - 0s - loss: 0.1164 - accuracy: 0.9667 - val_loss: 0.3513 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.84286\n",
      "Epoch 423/4000\n",
      " - 0s - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.3511 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.84286\n",
      "Epoch 424/4000\n",
      " - 0s - loss: 0.1160 - accuracy: 0.9667 - val_loss: 0.3509 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.84286\n",
      "Epoch 425/4000\n",
      " - 0s - loss: 0.1159 - accuracy: 0.9667 - val_loss: 0.3507 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.84286\n",
      "Epoch 426/4000\n",
      " - 0s - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.3505 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.84286\n",
      "Epoch 427/4000\n",
      " - 0s - loss: 0.1155 - accuracy: 0.9667 - val_loss: 0.3502 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.84286\n",
      "Epoch 428/4000\n",
      " - 0s - loss: 0.1153 - accuracy: 0.9667 - val_loss: 0.3500 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.84286\n",
      "Epoch 429/4000\n",
      " - 0s - loss: 0.1151 - accuracy: 0.9667 - val_loss: 0.3497 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.84286\n",
      "Epoch 430/4000\n",
      " - 0s - loss: 0.1149 - accuracy: 0.9667 - val_loss: 0.3494 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.84286\n",
      "Epoch 431/4000\n",
      " - 0s - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.3490 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.84286\n",
      "Epoch 432/4000\n",
      " - 0s - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.3487 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.84286\n",
      "Epoch 433/4000\n",
      " - 0s - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.3484 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.84286\n",
      "Epoch 434/4000\n",
      " - 0s - loss: 0.1142 - accuracy: 0.9667 - val_loss: 0.3481 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.84286\n",
      "Epoch 435/4000\n",
      " - 0s - loss: 0.1140 - accuracy: 0.9667 - val_loss: 0.3478 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.84286\n",
      "Epoch 436/4000\n",
      " - 0s - loss: 0.1138 - accuracy: 0.9667 - val_loss: 0.3475 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.84286\n",
      "Epoch 437/4000\n",
      " - 0s - loss: 0.1136 - accuracy: 0.9667 - val_loss: 0.3472 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.84286\n",
      "Epoch 438/4000\n",
      " - 0s - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.3469 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.84286\n",
      "Epoch 439/4000\n",
      " - 0s - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.3466 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.84286\n",
      "Epoch 440/4000\n",
      " - 0s - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.3463 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.84286\n",
      "Epoch 441/4000\n",
      " - 0s - loss: 0.1128 - accuracy: 0.9667 - val_loss: 0.3459 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.84286\n",
      "Epoch 442/4000\n",
      " - 0s - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.3456 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.84286\n",
      "Epoch 443/4000\n",
      " - 0s - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.3453 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.84286\n",
      "Epoch 444/4000\n",
      " - 0s - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.3450 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.84286\n",
      "Epoch 445/4000\n",
      " - 0s - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.3447 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.84286\n",
      "Epoch 446/4000\n",
      " - 0s - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.3443 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.84286\n",
      "Epoch 447/4000\n",
      " - 0s - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.3439 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.84286\n",
      "Epoch 448/4000\n",
      " - 0s - loss: 0.1114 - accuracy: 0.9667 - val_loss: 0.3435 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.84286\n",
      "Epoch 449/4000\n",
      " - 0s - loss: 0.1112 - accuracy: 0.9667 - val_loss: 0.3432 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.84286\n",
      "Epoch 450/4000\n",
      " - 0s - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.3429 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.84286\n",
      "Epoch 451/4000\n",
      " - 0s - loss: 0.1109 - accuracy: 0.9667 - val_loss: 0.3425 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.84286\n",
      "Epoch 452/4000\n",
      " - 0s - loss: 0.1107 - accuracy: 0.9667 - val_loss: 0.3422 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.84286\n",
      "Epoch 453/4000\n",
      " - 0s - loss: 0.1105 - accuracy: 0.9667 - val_loss: 0.3418 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.84286\n",
      "Epoch 454/4000\n",
      " - 0s - loss: 0.1102 - accuracy: 0.9667 - val_loss: 0.3414 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.84286\n",
      "Epoch 455/4000\n",
      " - 0s - loss: 0.1101 - accuracy: 0.9667 - val_loss: 0.3410 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.84286\n",
      "Epoch 456/4000\n",
      " - 0s - loss: 0.1099 - accuracy: 0.9667 - val_loss: 0.3406 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.84286\n",
      "Epoch 457/4000\n",
      " - 0s - loss: 0.1097 - accuracy: 0.9667 - val_loss: 0.3403 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.84286\n",
      "Epoch 458/4000\n",
      " - 0s - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.3399 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.84286\n",
      "Epoch 459/4000\n",
      " - 0s - loss: 0.1092 - accuracy: 0.9667 - val_loss: 0.3395 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.84286\n",
      "Epoch 460/4000\n",
      " - 0s - loss: 0.1090 - accuracy: 0.9667 - val_loss: 0.3391 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.84286\n",
      "Epoch 461/4000\n",
      " - 0s - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.3387 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.84286\n",
      "Epoch 462/4000\n",
      " - 0s - loss: 0.1086 - accuracy: 0.9667 - val_loss: 0.3383 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.84286\n",
      "Epoch 463/4000\n",
      " - 0s - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.3379 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.84286\n",
      "Epoch 464/4000\n",
      " - 0s - loss: 0.1082 - accuracy: 0.9667 - val_loss: 0.3375 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.84286\n",
      "Epoch 465/4000\n",
      " - 0s - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.3372 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.84286\n",
      "Epoch 466/4000\n",
      " - 0s - loss: 0.1078 - accuracy: 0.9667 - val_loss: 0.3369 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.84286\n",
      "Epoch 467/4000\n",
      " - 0s - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.3365 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.84286\n",
      "Epoch 468/4000\n",
      " - 0s - loss: 0.1074 - accuracy: 0.9667 - val_loss: 0.3360 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.84286\n",
      "Epoch 469/4000\n",
      " - 0s - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.3356 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.84286\n",
      "Epoch 470/4000\n",
      " - 0s - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.3351 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.84286\n",
      "Epoch 471/4000\n",
      " - 0s - loss: 0.1068 - accuracy: 0.9667 - val_loss: 0.3346 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.84286\n",
      "Epoch 472/4000\n",
      " - 0s - loss: 0.1066 - accuracy: 0.9667 - val_loss: 0.3343 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.84286\n",
      "Epoch 473/4000\n",
      " - 0s - loss: 0.1064 - accuracy: 0.9667 - val_loss: 0.3340 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.84286\n",
      "Epoch 474/4000\n",
      " - 0s - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.3337 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.84286\n",
      "Epoch 475/4000\n",
      " - 0s - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.3333 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.84286\n",
      "Epoch 476/4000\n",
      " - 0s - loss: 0.1058 - accuracy: 0.9667 - val_loss: 0.3328 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.84286\n",
      "Epoch 477/4000\n",
      " - 0s - loss: 0.1055 - accuracy: 0.9667 - val_loss: 0.3323 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.84286\n",
      "Epoch 478/4000\n",
      " - 0s - loss: 0.1053 - accuracy: 0.9667 - val_loss: 0.3317 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.84286\n",
      "Epoch 479/4000\n",
      " - 0s - loss: 0.1051 - accuracy: 0.9667 - val_loss: 0.3313 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.84286\n",
      "Epoch 480/4000\n",
      " - 0s - loss: 0.1049 - accuracy: 0.9667 - val_loss: 0.3311 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.84286\n",
      "Epoch 481/4000\n",
      " - 0s - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.3308 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.84286\n",
      "Epoch 482/4000\n",
      " - 0s - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.3305 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.84286\n",
      "Epoch 483/4000\n",
      " - 0s - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.3302 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.84286\n",
      "Epoch 484/4000\n",
      " - 0s - loss: 0.1041 - accuracy: 0.9667 - val_loss: 0.3298 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.84286\n",
      "Epoch 485/4000\n",
      " - 0s - loss: 0.1039 - accuracy: 0.9667 - val_loss: 0.3293 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.84286\n",
      "Epoch 486/4000\n",
      " - 0s - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.3289 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.84286\n",
      "Epoch 487/4000\n",
      " - 0s - loss: 0.1034 - accuracy: 0.9667 - val_loss: 0.3284 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.84286\n",
      "Epoch 488/4000\n",
      " - 0s - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.3279 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.84286\n",
      "Epoch 489/4000\n",
      " - 0s - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.3275 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.84286\n",
      "Epoch 490/4000\n",
      " - 0s - loss: 0.1028 - accuracy: 0.9667 - val_loss: 0.3271 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.84286\n",
      "Epoch 491/4000\n",
      " - 0s - loss: 0.1026 - accuracy: 0.9667 - val_loss: 0.3268 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.84286\n",
      "Epoch 492/4000\n",
      " - 0s - loss: 0.1024 - accuracy: 0.9667 - val_loss: 0.3265 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.84286\n",
      "Epoch 493/4000\n",
      " - 0s - loss: 0.1021 - accuracy: 0.9667 - val_loss: 0.3261 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.84286\n",
      "Epoch 494/4000\n",
      " - 0s - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.3257 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.84286\n",
      "Epoch 495/4000\n",
      " - 0s - loss: 0.1017 - accuracy: 0.9667 - val_loss: 0.3253 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.84286\n",
      "Epoch 496/4000\n",
      " - 0s - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.3249 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.84286\n",
      "Epoch 497/4000\n",
      " - 0s - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.3244 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.84286\n",
      "Epoch 498/4000\n",
      " - 0s - loss: 0.1010 - accuracy: 0.9667 - val_loss: 0.3239 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.84286\n",
      "Epoch 499/4000\n",
      " - 0s - loss: 0.1008 - accuracy: 0.9667 - val_loss: 0.3234 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.84286\n",
      "Epoch 500/4000\n",
      " - 0s - loss: 0.1006 - accuracy: 0.9667 - val_loss: 0.3230 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.84286\n",
      "Epoch 501/4000\n",
      " - 0s - loss: 0.1003 - accuracy: 0.9667 - val_loss: 0.3226 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00501: val_accuracy did not improve from 0.84286\n",
      "Epoch 502/4000\n",
      " - 0s - loss: 0.1001 - accuracy: 0.9667 - val_loss: 0.3223 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00502: val_accuracy did not improve from 0.84286\n",
      "Epoch 503/4000\n",
      " - 0s - loss: 0.0999 - accuracy: 0.9667 - val_loss: 0.3220 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00503: val_accuracy did not improve from 0.84286\n",
      "Epoch 504/4000\n",
      " - 0s - loss: 0.0997 - accuracy: 0.9667 - val_loss: 0.3216 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00504: val_accuracy did not improve from 0.84286\n",
      "Epoch 505/4000\n",
      " - 0s - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.3210 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00505: val_accuracy did not improve from 0.84286\n",
      "Epoch 506/4000\n",
      " - 0s - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.3205 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00506: val_accuracy did not improve from 0.84286\n",
      "Epoch 507/4000\n",
      " - 0s - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.3201 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00507: val_accuracy did not improve from 0.84286\n",
      "Epoch 508/4000\n",
      " - 0s - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.3197 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00508: val_accuracy did not improve from 0.84286\n",
      "Epoch 509/4000\n",
      " - 0s - loss: 0.0985 - accuracy: 0.9667 - val_loss: 0.3192 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00509: val_accuracy did not improve from 0.84286\n",
      "Epoch 510/4000\n",
      " - 0s - loss: 0.0983 - accuracy: 0.9667 - val_loss: 0.3188 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00510: val_accuracy did not improve from 0.84286\n",
      "Epoch 511/4000\n",
      " - 0s - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.3184 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00511: val_accuracy did not improve from 0.84286\n",
      "Epoch 512/4000\n",
      " - 0s - loss: 0.0979 - accuracy: 0.9667 - val_loss: 0.3181 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00512: val_accuracy did not improve from 0.84286\n",
      "Epoch 513/4000\n",
      " - 0s - loss: 0.0976 - accuracy: 0.9667 - val_loss: 0.3177 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00513: val_accuracy did not improve from 0.84286\n",
      "Epoch 514/4000\n",
      " - 0s - loss: 0.0974 - accuracy: 0.9667 - val_loss: 0.3173 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00514: val_accuracy did not improve from 0.84286\n",
      "Epoch 515/4000\n",
      " - 0s - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.3168 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00515: val_accuracy did not improve from 0.84286\n",
      "Epoch 516/4000\n",
      " - 0s - loss: 0.0969 - accuracy: 0.9667 - val_loss: 0.3163 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00516: val_accuracy did not improve from 0.84286\n",
      "Epoch 517/4000\n",
      " - 0s - loss: 0.0967 - accuracy: 0.9667 - val_loss: 0.3158 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00517: val_accuracy did not improve from 0.84286\n",
      "Epoch 518/4000\n",
      " - 0s - loss: 0.0965 - accuracy: 0.9667 - val_loss: 0.3154 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00518: val_accuracy did not improve from 0.84286\n",
      "Epoch 519/4000\n",
      " - 0s - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.3149 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00519: val_accuracy improved from 0.84286 to 0.85714, saving model to best_model.h5\n",
      "Epoch 520/4000\n",
      " - 0s - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.3145 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00520: val_accuracy did not improve from 0.85714\n",
      "Epoch 521/4000\n",
      " - 0s - loss: 0.0957 - accuracy: 0.9667 - val_loss: 0.3141 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00521: val_accuracy did not improve from 0.85714\n",
      "Epoch 522/4000\n",
      " - 0s - loss: 0.0955 - accuracy: 0.9667 - val_loss: 0.3137 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00522: val_accuracy did not improve from 0.85714\n",
      "Epoch 523/4000\n",
      " - 0s - loss: 0.0953 - accuracy: 0.9667 - val_loss: 0.3133 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00523: val_accuracy did not improve from 0.85714\n",
      "Epoch 524/4000\n",
      " - 0s - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.3128 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00524: val_accuracy did not improve from 0.85714\n",
      "Epoch 525/4000\n",
      " - 0s - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.3123 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00525: val_accuracy did not improve from 0.85714\n",
      "Epoch 526/4000\n",
      " - 0s - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.3118 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00526: val_accuracy did not improve from 0.85714\n",
      "Epoch 527/4000\n",
      " - 0s - loss: 0.0943 - accuracy: 0.9667 - val_loss: 0.3113 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00527: val_accuracy did not improve from 0.85714\n",
      "Epoch 528/4000\n",
      " - 0s - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.3109 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00528: val_accuracy did not improve from 0.85714\n",
      "Epoch 529/4000\n",
      " - 0s - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.3105 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00529: val_accuracy did not improve from 0.85714\n",
      "Epoch 530/4000\n",
      " - 0s - loss: 0.0936 - accuracy: 0.9667 - val_loss: 0.3100 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00530: val_accuracy did not improve from 0.85714\n",
      "Epoch 531/4000\n",
      " - 0s - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.3096 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00531: val_accuracy did not improve from 0.85714\n",
      "Epoch 532/4000\n",
      " - 0s - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.3091 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00532: val_accuracy did not improve from 0.85714\n",
      "Epoch 533/4000\n",
      " - 0s - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.3086 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00533: val_accuracy did not improve from 0.85714\n",
      "Epoch 534/4000\n",
      " - 0s - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.3082 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00534: val_accuracy did not improve from 0.85714\n",
      "Epoch 535/4000\n",
      " - 0s - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.3077 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00535: val_accuracy did not improve from 0.85714\n",
      "Epoch 536/4000\n",
      " - 0s - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.3073 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00536: val_accuracy did not improve from 0.85714\n",
      "Epoch 537/4000\n",
      " - 0s - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.3068 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00537: val_accuracy improved from 0.85714 to 0.87143, saving model to best_model.h5\n",
      "Epoch 538/4000\n",
      " - 0s - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.3063 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00538: val_accuracy did not improve from 0.87143\n",
      "Epoch 539/4000\n",
      " - 0s - loss: 0.0914 - accuracy: 0.9667 - val_loss: 0.3057 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00539: val_accuracy did not improve from 0.87143\n",
      "Epoch 540/4000\n",
      " - 0s - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.3052 - val_accuracy: 0.8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00540: val_accuracy did not improve from 0.87143\n",
      "Epoch 541/4000\n",
      " - 0s - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.3048 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00541: val_accuracy did not improve from 0.87143\n",
      "Epoch 542/4000\n",
      " - 0s - loss: 0.0907 - accuracy: 0.9667 - val_loss: 0.3044 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00542: val_accuracy did not improve from 0.87143\n",
      "Epoch 543/4000\n",
      " - 0s - loss: 0.0904 - accuracy: 0.9667 - val_loss: 0.3039 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00543: val_accuracy did not improve from 0.87143\n",
      "Epoch 544/4000\n",
      " - 0s - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.3034 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00544: val_accuracy did not improve from 0.87143\n",
      "Epoch 545/4000\n",
      " - 0s - loss: 0.0899 - accuracy: 0.9667 - val_loss: 0.3029 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00545: val_accuracy improved from 0.87143 to 0.88571, saving model to best_model.h5\n",
      "Epoch 546/4000\n",
      " - 0s - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.3023 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00546: val_accuracy did not improve from 0.88571\n",
      "Epoch 547/4000\n",
      " - 0s - loss: 0.0894 - accuracy: 0.9667 - val_loss: 0.3018 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00547: val_accuracy did not improve from 0.88571\n",
      "Epoch 548/4000\n",
      " - 0s - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.3014 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00548: val_accuracy did not improve from 0.88571\n",
      "Epoch 549/4000\n",
      " - 0s - loss: 0.0889 - accuracy: 0.9667 - val_loss: 0.3010 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00549: val_accuracy did not improve from 0.88571\n",
      "Epoch 550/4000\n",
      " - 0s - loss: 0.0887 - accuracy: 0.9667 - val_loss: 0.3006 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00550: val_accuracy did not improve from 0.88571\n",
      "Epoch 551/4000\n",
      " - 0s - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.3001 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00551: val_accuracy did not improve from 0.88571\n",
      "Epoch 552/4000\n",
      " - 0s - loss: 0.0882 - accuracy: 0.9667 - val_loss: 0.2997 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00552: val_accuracy did not improve from 0.88571\n",
      "Epoch 553/4000\n",
      " - 0s - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.2992 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00553: val_accuracy did not improve from 0.88571\n",
      "Epoch 554/4000\n",
      " - 0s - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.2987 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00554: val_accuracy did not improve from 0.88571\n",
      "Epoch 555/4000\n",
      " - 0s - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.2982 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00555: val_accuracy did not improve from 0.88571\n",
      "Epoch 556/4000\n",
      " - 0s - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.2977 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00556: val_accuracy did not improve from 0.88571\n",
      "Epoch 557/4000\n",
      " - 0s - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.2972 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00557: val_accuracy did not improve from 0.88571\n",
      "Epoch 558/4000\n",
      " - 0s - loss: 0.0867 - accuracy: 0.9667 - val_loss: 0.2967 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00558: val_accuracy did not improve from 0.88571\n",
      "Epoch 559/4000\n",
      " - 0s - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.2963 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00559: val_accuracy did not improve from 0.88571\n",
      "Epoch 560/4000\n",
      " - 0s - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.2958 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00560: val_accuracy did not improve from 0.88571\n",
      "Epoch 561/4000\n",
      " - 0s - loss: 0.0859 - accuracy: 0.9667 - val_loss: 0.2954 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00561: val_accuracy did not improve from 0.88571\n",
      "Epoch 562/4000\n",
      " - 0s - loss: 0.0857 - accuracy: 0.9667 - val_loss: 0.2950 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00562: val_accuracy did not improve from 0.88571\n",
      "Epoch 563/4000\n",
      " - 0s - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.2946 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00563: val_accuracy did not improve from 0.88571\n",
      "Epoch 564/4000\n",
      " - 0s - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.2941 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00564: val_accuracy did not improve from 0.88571\n",
      "Epoch 565/4000\n",
      " - 0s - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.2936 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00565: val_accuracy did not improve from 0.88571\n",
      "Epoch 566/4000\n",
      " - 0s - loss: 0.0846 - accuracy: 0.9667 - val_loss: 0.2931 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00566: val_accuracy did not improve from 0.88571\n",
      "Epoch 567/4000\n",
      " - 0s - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.2927 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00567: val_accuracy did not improve from 0.88571\n",
      "Epoch 568/4000\n",
      " - 0s - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.2923 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00568: val_accuracy did not improve from 0.88571\n",
      "Epoch 569/4000\n",
      " - 0s - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.2919 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00569: val_accuracy did not improve from 0.88571\n",
      "Epoch 570/4000\n",
      " - 0s - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.2914 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00570: val_accuracy did not improve from 0.88571\n",
      "Epoch 571/4000\n",
      " - 0s - loss: 0.0833 - accuracy: 0.9667 - val_loss: 0.2910 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00571: val_accuracy did not improve from 0.88571\n",
      "Epoch 572/4000\n",
      " - 0s - loss: 0.0831 - accuracy: 0.9667 - val_loss: 0.2905 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00572: val_accuracy did not improve from 0.88571\n",
      "Epoch 573/4000\n",
      " - 0s - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.2900 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00573: val_accuracy did not improve from 0.88571\n",
      "Epoch 574/4000\n",
      " - 0s - loss: 0.0825 - accuracy: 0.9667 - val_loss: 0.2896 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00574: val_accuracy did not improve from 0.88571\n",
      "Epoch 575/4000\n",
      " - 0s - loss: 0.0823 - accuracy: 0.9667 - val_loss: 0.2892 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00575: val_accuracy did not improve from 0.88571\n",
      "Epoch 576/4000\n",
      " - 0s - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.2888 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00576: val_accuracy did not improve from 0.88571\n",
      "Epoch 577/4000\n",
      " - 0s - loss: 0.0818 - accuracy: 0.9667 - val_loss: 0.2883 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00577: val_accuracy did not improve from 0.88571\n",
      "Epoch 578/4000\n",
      " - 0s - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.2878 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00578: val_accuracy did not improve from 0.88571\n",
      "Epoch 579/4000\n",
      " - 0s - loss: 0.0813 - accuracy: 0.9667 - val_loss: 0.2873 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00579: val_accuracy did not improve from 0.88571\n",
      "Epoch 580/4000\n",
      " - 0s - loss: 0.0810 - accuracy: 0.9667 - val_loss: 0.2868 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00580: val_accuracy did not improve from 0.88571\n",
      "Epoch 581/4000\n",
      " - 0s - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.2864 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00581: val_accuracy did not improve from 0.88571\n",
      "Epoch 582/4000\n",
      " - 0s - loss: 0.0805 - accuracy: 0.9667 - val_loss: 0.2860 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00582: val_accuracy did not improve from 0.88571\n",
      "Epoch 583/4000\n",
      " - 0s - loss: 0.0802 - accuracy: 0.9667 - val_loss: 0.2857 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00583: val_accuracy did not improve from 0.88571\n",
      "Epoch 584/4000\n",
      " - 0s - loss: 0.0800 - accuracy: 0.9667 - val_loss: 0.2854 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00584: val_accuracy did not improve from 0.88571\n",
      "Epoch 585/4000\n",
      " - 0s - loss: 0.0797 - accuracy: 0.9667 - val_loss: 0.2850 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00585: val_accuracy did not improve from 0.88571\n",
      "Epoch 586/4000\n",
      " - 0s - loss: 0.0795 - accuracy: 0.9667 - val_loss: 0.2844 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00586: val_accuracy did not improve from 0.88571\n",
      "Epoch 587/4000\n",
      " - 0s - loss: 0.0792 - accuracy: 0.9667 - val_loss: 0.2839 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00587: val_accuracy did not improve from 0.88571\n",
      "Epoch 588/4000\n",
      " - 0s - loss: 0.0790 - accuracy: 0.9667 - val_loss: 0.2834 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00588: val_accuracy did not improve from 0.88571\n",
      "Epoch 589/4000\n",
      " - 0s - loss: 0.0787 - accuracy: 0.9667 - val_loss: 0.2830 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00589: val_accuracy improved from 0.88571 to 0.90000, saving model to best_model.h5\n",
      "Epoch 590/4000\n",
      " - 0s - loss: 0.0785 - accuracy: 0.9667 - val_loss: 0.2826 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00590: val_accuracy did not improve from 0.90000\n",
      "Epoch 591/4000\n",
      " - 0s - loss: 0.0782 - accuracy: 0.9667 - val_loss: 0.2822 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00591: val_accuracy did not improve from 0.90000\n",
      "Epoch 592/4000\n",
      " - 0s - loss: 0.0780 - accuracy: 0.9667 - val_loss: 0.2818 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00592: val_accuracy did not improve from 0.90000\n",
      "Epoch 593/4000\n",
      " - 0s - loss: 0.0777 - accuracy: 0.9667 - val_loss: 0.2814 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00593: val_accuracy did not improve from 0.90000\n",
      "Epoch 594/4000\n",
      " - 0s - loss: 0.0774 - accuracy: 0.9667 - val_loss: 0.2809 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00594: val_accuracy did not improve from 0.90000\n",
      "Epoch 595/4000\n",
      " - 0s - loss: 0.0772 - accuracy: 0.9667 - val_loss: 0.2804 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00595: val_accuracy did not improve from 0.90000\n",
      "Epoch 596/4000\n",
      " - 0s - loss: 0.0769 - accuracy: 0.9667 - val_loss: 0.2799 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00596: val_accuracy did not improve from 0.90000\n",
      "Epoch 597/4000\n",
      " - 0s - loss: 0.0767 - accuracy: 0.9667 - val_loss: 0.2795 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00597: val_accuracy did not improve from 0.90000\n",
      "Epoch 598/4000\n",
      " - 0s - loss: 0.0764 - accuracy: 0.9667 - val_loss: 0.2791 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00598: val_accuracy did not improve from 0.90000\n",
      "Epoch 599/4000\n",
      " - 0s - loss: 0.0762 - accuracy: 0.9667 - val_loss: 0.2787 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00599: val_accuracy did not improve from 0.90000\n",
      "Epoch 600/4000\n",
      " - 0s - loss: 0.0759 - accuracy: 0.9667 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00600: val_accuracy did not improve from 0.90000\n",
      "Epoch 601/4000\n",
      " - 0s - loss: 0.0757 - accuracy: 0.9667 - val_loss: 0.2780 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00601: val_accuracy did not improve from 0.90000\n",
      "Epoch 602/4000\n",
      " - 0s - loss: 0.0754 - accuracy: 0.9667 - val_loss: 0.2777 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00602: val_accuracy did not improve from 0.90000\n",
      "Epoch 603/4000\n",
      " - 0s - loss: 0.0752 - accuracy: 0.9667 - val_loss: 0.2773 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00603: val_accuracy did not improve from 0.90000\n",
      "Epoch 604/4000\n",
      " - 0s - loss: 0.0749 - accuracy: 0.9667 - val_loss: 0.2768 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00604: val_accuracy did not improve from 0.90000\n",
      "Epoch 605/4000\n",
      " - 0s - loss: 0.0747 - accuracy: 0.9667 - val_loss: 0.2763 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00605: val_accuracy did not improve from 0.90000\n",
      "Epoch 606/4000\n",
      " - 0s - loss: 0.0744 - accuracy: 0.9667 - val_loss: 0.2758 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00606: val_accuracy did not improve from 0.90000\n",
      "Epoch 607/4000\n",
      " - 0s - loss: 0.0741 - accuracy: 0.9667 - val_loss: 0.2754 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00607: val_accuracy did not improve from 0.90000\n",
      "Epoch 608/4000\n",
      " - 0s - loss: 0.0739 - accuracy: 0.9667 - val_loss: 0.2750 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00608: val_accuracy did not improve from 0.90000\n",
      "Epoch 609/4000\n",
      " - 0s - loss: 0.0736 - accuracy: 0.9667 - val_loss: 0.2746 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00609: val_accuracy did not improve from 0.90000\n",
      "Epoch 610/4000\n",
      " - 0s - loss: 0.0734 - accuracy: 0.9667 - val_loss: 0.2743 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00610: val_accuracy did not improve from 0.90000\n",
      "Epoch 611/4000\n",
      " - 0s - loss: 0.0731 - accuracy: 0.9667 - val_loss: 0.2739 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00611: val_accuracy did not improve from 0.90000\n",
      "Epoch 612/4000\n",
      " - 0s - loss: 0.0729 - accuracy: 0.9667 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00612: val_accuracy did not improve from 0.90000\n",
      "Epoch 613/4000\n",
      " - 0s - loss: 0.0726 - accuracy: 0.9667 - val_loss: 0.2734 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00613: val_accuracy did not improve from 0.90000\n",
      "Epoch 614/4000\n",
      " - 0s - loss: 0.0724 - accuracy: 0.9667 - val_loss: 0.2731 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00614: val_accuracy did not improve from 0.90000\n",
      "Epoch 615/4000\n",
      " - 0s - loss: 0.0721 - accuracy: 0.9667 - val_loss: 0.2727 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00615: val_accuracy did not improve from 0.90000\n",
      "Epoch 616/4000\n",
      " - 0s - loss: 0.0719 - accuracy: 0.9667 - val_loss: 0.2723 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00616: val_accuracy did not improve from 0.90000\n",
      "Epoch 617/4000\n",
      " - 0s - loss: 0.0716 - accuracy: 0.9667 - val_loss: 0.2719 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00617: val_accuracy did not improve from 0.90000\n",
      "Epoch 618/4000\n",
      " - 0s - loss: 0.0714 - accuracy: 0.9667 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00618: val_accuracy did not improve from 0.90000\n",
      "Epoch 619/4000\n",
      " - 0s - loss: 0.0711 - accuracy: 0.9667 - val_loss: 0.2711 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00619: val_accuracy did not improve from 0.90000\n",
      "Epoch 620/4000\n",
      " - 0s - loss: 0.0709 - accuracy: 0.9667 - val_loss: 0.2708 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00620: val_accuracy did not improve from 0.90000\n",
      "Epoch 621/4000\n",
      " - 0s - loss: 0.0706 - accuracy: 0.9667 - val_loss: 0.2706 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00621: val_accuracy did not improve from 0.90000\n",
      "Epoch 622/4000\n",
      " - 0s - loss: 0.0704 - accuracy: 0.9667 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00622: val_accuracy did not improve from 0.90000\n",
      "Epoch 623/4000\n",
      " - 0s - loss: 0.0701 - accuracy: 0.9667 - val_loss: 0.2701 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00623: val_accuracy did not improve from 0.90000\n",
      "Epoch 624/4000\n",
      " - 0s - loss: 0.0699 - accuracy: 0.9667 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00624: val_accuracy did not improve from 0.90000\n",
      "Epoch 625/4000\n",
      " - 0s - loss: 0.0696 - accuracy: 0.9667 - val_loss: 0.2694 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00625: val_accuracy did not improve from 0.90000\n",
      "Epoch 626/4000\n",
      " - 0s - loss: 0.0694 - accuracy: 0.9667 - val_loss: 0.2690 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00626: val_accuracy did not improve from 0.90000\n",
      "Epoch 627/4000\n",
      " - 0s - loss: 0.0691 - accuracy: 0.9667 - val_loss: 0.2687 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00627: val_accuracy did not improve from 0.90000\n",
      "Epoch 628/4000\n",
      " - 0s - loss: 0.0689 - accuracy: 0.9667 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00628: val_accuracy did not improve from 0.90000\n",
      "Epoch 629/4000\n",
      " - 0s - loss: 0.0686 - accuracy: 0.9667 - val_loss: 0.2680 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00629: val_accuracy did not improve from 0.90000\n",
      "Epoch 630/4000\n",
      " - 0s - loss: 0.0684 - accuracy: 0.9667 - val_loss: 0.2677 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00630: val_accuracy did not improve from 0.90000\n",
      "Epoch 631/4000\n",
      " - 0s - loss: 0.0681 - accuracy: 0.9667 - val_loss: 0.2673 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00631: val_accuracy improved from 0.90000 to 0.91429, saving model to best_model.h5\n",
      "Epoch 632/4000\n",
      " - 0s - loss: 0.0679 - accuracy: 0.9667 - val_loss: 0.2670 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00632: val_accuracy did not improve from 0.91429\n",
      "Epoch 633/4000\n",
      " - 0s - loss: 0.0677 - accuracy: 0.9667 - val_loss: 0.2667 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00633: val_accuracy did not improve from 0.91429\n",
      "Epoch 634/4000\n",
      " - 0s - loss: 0.0674 - accuracy: 0.9667 - val_loss: 0.2663 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00634: val_accuracy did not improve from 0.91429\n",
      "Epoch 635/4000\n",
      " - 0s - loss: 0.0672 - accuracy: 0.9667 - val_loss: 0.2660 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00635: val_accuracy did not improve from 0.91429\n",
      "Epoch 636/4000\n",
      " - 0s - loss: 0.0669 - accuracy: 0.9667 - val_loss: 0.2657 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00636: val_accuracy did not improve from 0.91429\n",
      "Epoch 637/4000\n",
      " - 0s - loss: 0.0666 - accuracy: 0.9667 - val_loss: 0.2654 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00637: val_accuracy did not improve from 0.91429\n",
      "Epoch 638/4000\n",
      " - 0s - loss: 0.0664 - accuracy: 0.9667 - val_loss: 0.2651 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00638: val_accuracy did not improve from 0.91429\n",
      "Epoch 639/4000\n",
      " - 0s - loss: 0.0662 - accuracy: 0.9667 - val_loss: 0.2648 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00639: val_accuracy did not improve from 0.91429\n",
      "Epoch 640/4000\n",
      " - 0s - loss: 0.0659 - accuracy: 0.9667 - val_loss: 0.2645 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00640: val_accuracy did not improve from 0.91429\n",
      "Epoch 641/4000\n",
      " - 0s - loss: 0.0657 - accuracy: 0.9667 - val_loss: 0.2643 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00641: val_accuracy did not improve from 0.91429\n",
      "Epoch 642/4000\n",
      " - 0s - loss: 0.0654 - accuracy: 0.9667 - val_loss: 0.2640 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00642: val_accuracy improved from 0.91429 to 0.92857, saving model to best_model.h5\n",
      "Epoch 643/4000\n",
      " - 0s - loss: 0.0652 - accuracy: 0.9667 - val_loss: 0.2636 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00643: val_accuracy did not improve from 0.92857\n",
      "Epoch 644/4000\n",
      " - 0s - loss: 0.0649 - accuracy: 0.9667 - val_loss: 0.2633 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00644: val_accuracy did not improve from 0.92857\n",
      "Epoch 645/4000\n",
      " - 0s - loss: 0.0647 - accuracy: 0.9667 - val_loss: 0.2630 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00645: val_accuracy did not improve from 0.92857\n",
      "Epoch 646/4000\n",
      " - 0s - loss: 0.0645 - accuracy: 0.9667 - val_loss: 0.2627 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00646: val_accuracy did not improve from 0.92857\n",
      "Epoch 647/4000\n",
      " - 0s - loss: 0.0642 - accuracy: 0.9667 - val_loss: 0.2625 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00647: val_accuracy did not improve from 0.92857\n",
      "Epoch 648/4000\n",
      " - 0s - loss: 0.0640 - accuracy: 0.9667 - val_loss: 0.2623 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00648: val_accuracy did not improve from 0.92857\n",
      "Epoch 649/4000\n",
      " - 0s - loss: 0.0637 - accuracy: 0.9667 - val_loss: 0.2620 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00649: val_accuracy did not improve from 0.92857\n",
      "Epoch 650/4000\n",
      " - 0s - loss: 0.0635 - accuracy: 0.9667 - val_loss: 0.2617 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00650: val_accuracy did not improve from 0.92857\n",
      "Epoch 651/4000\n",
      " - 0s - loss: 0.0633 - accuracy: 0.9667 - val_loss: 0.2614 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00651: val_accuracy did not improve from 0.92857\n",
      "Epoch 652/4000\n",
      " - 0s - loss: 0.0630 - accuracy: 0.9667 - val_loss: 0.2610 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00652: val_accuracy did not improve from 0.92857\n",
      "Epoch 653/4000\n",
      " - 0s - loss: 0.0628 - accuracy: 0.9667 - val_loss: 0.2607 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00653: val_accuracy did not improve from 0.92857\n",
      "Epoch 654/4000\n",
      " - 0s - loss: 0.0625 - accuracy: 0.9667 - val_loss: 0.2605 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00654: val_accuracy did not improve from 0.92857\n",
      "Epoch 655/4000\n",
      " - 0s - loss: 0.0623 - accuracy: 0.9667 - val_loss: 0.2603 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00655: val_accuracy did not improve from 0.92857\n",
      "Epoch 656/4000\n",
      " - 0s - loss: 0.0621 - accuracy: 0.9667 - val_loss: 0.2601 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00656: val_accuracy did not improve from 0.92857\n",
      "Epoch 657/4000\n",
      " - 0s - loss: 0.0618 - accuracy: 0.9667 - val_loss: 0.2599 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00657: val_accuracy did not improve from 0.92857\n",
      "Epoch 658/4000\n",
      " - 0s - loss: 0.0616 - accuracy: 0.9667 - val_loss: 0.2596 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00658: val_accuracy did not improve from 0.92857\n",
      "Epoch 659/4000\n",
      " - 0s - loss: 0.0614 - accuracy: 0.9667 - val_loss: 0.2592 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00659: val_accuracy did not improve from 0.92857\n",
      "Epoch 660/4000\n",
      " - 0s - loss: 0.0611 - accuracy: 0.9667 - val_loss: 0.2589 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00660: val_accuracy did not improve from 0.92857\n",
      "Epoch 661/4000\n",
      " - 0s - loss: 0.0609 - accuracy: 0.9667 - val_loss: 0.2585 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00661: val_accuracy did not improve from 0.92857\n",
      "Epoch 662/4000\n",
      " - 0s - loss: 0.0607 - accuracy: 0.9667 - val_loss: 0.2582 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00662: val_accuracy did not improve from 0.92857\n",
      "Epoch 663/4000\n",
      " - 0s - loss: 0.0605 - accuracy: 0.9667 - val_loss: 0.2579 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00663: val_accuracy did not improve from 0.92857\n",
      "Epoch 664/4000\n",
      " - 0s - loss: 0.0602 - accuracy: 0.9667 - val_loss: 0.2576 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00664: val_accuracy did not improve from 0.92857\n",
      "Epoch 665/4000\n",
      " - 0s - loss: 0.0600 - accuracy: 0.9667 - val_loss: 0.2573 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00665: val_accuracy did not improve from 0.92857\n",
      "Epoch 666/4000\n",
      " - 0s - loss: 0.0598 - accuracy: 0.9667 - val_loss: 0.2570 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00666: val_accuracy did not improve from 0.92857\n",
      "Epoch 667/4000\n",
      " - 0s - loss: 0.0596 - accuracy: 0.9667 - val_loss: 0.2567 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00667: val_accuracy did not improve from 0.92857\n",
      "Epoch 668/4000\n",
      " - 0s - loss: 0.0594 - accuracy: 0.9667 - val_loss: 0.2564 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00668: val_accuracy did not improve from 0.92857\n",
      "Epoch 669/4000\n",
      " - 0s - loss: 0.0591 - accuracy: 0.9667 - val_loss: 0.2560 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00669: val_accuracy did not improve from 0.92857\n",
      "Epoch 670/4000\n",
      " - 0s - loss: 0.0589 - accuracy: 0.9667 - val_loss: 0.2557 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00670: val_accuracy did not improve from 0.92857\n",
      "Epoch 671/4000\n",
      " - 0s - loss: 0.0587 - accuracy: 0.9667 - val_loss: 0.2553 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00671: val_accuracy did not improve from 0.92857\n",
      "Epoch 672/4000\n",
      " - 0s - loss: 0.0585 - accuracy: 0.9667 - val_loss: 0.2550 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00672: val_accuracy did not improve from 0.92857\n",
      "Epoch 673/4000\n",
      " - 0s - loss: 0.0582 - accuracy: 0.9667 - val_loss: 0.2547 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00673: val_accuracy did not improve from 0.92857\n",
      "Epoch 674/4000\n",
      " - 0s - loss: 0.0580 - accuracy: 0.9667 - val_loss: 0.2544 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00674: val_accuracy did not improve from 0.92857\n",
      "Epoch 675/4000\n",
      " - 0s - loss: 0.0578 - accuracy: 0.9667 - val_loss: 0.2541 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00675: val_accuracy did not improve from 0.92857\n",
      "Epoch 676/4000\n",
      " - 0s - loss: 0.0576 - accuracy: 0.9667 - val_loss: 0.2538 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00676: val_accuracy did not improve from 0.92857\n",
      "Epoch 677/4000\n",
      " - 0s - loss: 0.0574 - accuracy: 0.9667 - val_loss: 0.2535 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00677: val_accuracy did not improve from 0.92857\n",
      "Epoch 678/4000\n",
      " - 0s - loss: 0.0571 - accuracy: 0.9667 - val_loss: 0.2532 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00678: val_accuracy did not improve from 0.92857\n",
      "Epoch 679/4000\n",
      " - 0s - loss: 0.0569 - accuracy: 0.9667 - val_loss: 0.2529 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00679: val_accuracy did not improve from 0.92857\n",
      "Epoch 680/4000\n",
      " - 0s - loss: 0.0567 - accuracy: 0.9667 - val_loss: 0.2526 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00680: val_accuracy did not improve from 0.92857\n",
      "Epoch 681/4000\n",
      " - 0s - loss: 0.0565 - accuracy: 0.9667 - val_loss: 0.2523 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00681: val_accuracy did not improve from 0.92857\n",
      "Epoch 682/4000\n",
      " - 0s - loss: 0.0563 - accuracy: 0.9667 - val_loss: 0.2521 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00682: val_accuracy did not improve from 0.92857\n",
      "Epoch 683/4000\n",
      " - 0s - loss: 0.0560 - accuracy: 0.9667 - val_loss: 0.2518 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00683: val_accuracy did not improve from 0.92857\n",
      "Epoch 684/4000\n",
      " - 0s - loss: 0.0558 - accuracy: 0.9667 - val_loss: 0.2515 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00684: val_accuracy did not improve from 0.92857\n",
      "Epoch 685/4000\n",
      " - 0s - loss: 0.0556 - accuracy: 0.9667 - val_loss: 0.2513 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00685: val_accuracy did not improve from 0.92857\n",
      "Epoch 686/4000\n",
      " - 0s - loss: 0.0554 - accuracy: 0.9667 - val_loss: 0.2509 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00686: val_accuracy did not improve from 0.92857\n",
      "Epoch 687/4000\n",
      " - 0s - loss: 0.0552 - accuracy: 0.9667 - val_loss: 0.2506 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00687: val_accuracy did not improve from 0.92857\n",
      "Epoch 688/4000\n",
      " - 0s - loss: 0.0550 - accuracy: 0.9667 - val_loss: 0.2503 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00688: val_accuracy did not improve from 0.92857\n",
      "Epoch 689/4000\n",
      " - 0s - loss: 0.0548 - accuracy: 0.9667 - val_loss: 0.2501 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00689: val_accuracy did not improve from 0.92857\n",
      "Epoch 690/4000\n",
      " - 0s - loss: 0.0545 - accuracy: 0.9667 - val_loss: 0.2498 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00690: val_accuracy did not improve from 0.92857\n",
      "Epoch 691/4000\n",
      " - 0s - loss: 0.0543 - accuracy: 0.9667 - val_loss: 0.2495 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00691: val_accuracy did not improve from 0.92857\n",
      "Epoch 692/4000\n",
      " - 0s - loss: 0.0541 - accuracy: 0.9667 - val_loss: 0.2493 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00692: val_accuracy did not improve from 0.92857\n",
      "Epoch 693/4000\n",
      " - 0s - loss: 0.0539 - accuracy: 0.9667 - val_loss: 0.2490 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00693: val_accuracy did not improve from 0.92857\n",
      "Epoch 694/4000\n",
      " - 0s - loss: 0.0537 - accuracy: 0.9667 - val_loss: 0.2488 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00694: val_accuracy did not improve from 0.92857\n",
      "Epoch 695/4000\n",
      " - 0s - loss: 0.0535 - accuracy: 0.9667 - val_loss: 0.2486 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00695: val_accuracy did not improve from 0.92857\n",
      "Epoch 696/4000\n",
      " - 0s - loss: 0.0533 - accuracy: 0.9667 - val_loss: 0.2484 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00696: val_accuracy did not improve from 0.92857\n",
      "Epoch 697/4000\n",
      " - 0s - loss: 0.0531 - accuracy: 0.9667 - val_loss: 0.2481 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00697: val_accuracy did not improve from 0.92857\n",
      "Epoch 698/4000\n",
      " - 0s - loss: 0.0529 - accuracy: 0.9667 - val_loss: 0.2478 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00698: val_accuracy did not improve from 0.92857\n",
      "Epoch 699/4000\n",
      " - 0s - loss: 0.0527 - accuracy: 0.9667 - val_loss: 0.2475 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00699: val_accuracy did not improve from 0.92857\n",
      "Epoch 700/4000\n",
      " - 0s - loss: 0.0525 - accuracy: 0.9667 - val_loss: 0.2472 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00700: val_accuracy did not improve from 0.92857\n",
      "Epoch 701/4000\n",
      " - 0s - loss: 0.0523 - accuracy: 0.9667 - val_loss: 0.2470 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00701: val_accuracy did not improve from 0.92857\n",
      "Epoch 702/4000\n",
      " - 0s - loss: 0.0520 - accuracy: 0.9667 - val_loss: 0.2469 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00702: val_accuracy did not improve from 0.92857\n",
      "Epoch 703/4000\n",
      " - 0s - loss: 0.0518 - accuracy: 0.9667 - val_loss: 0.2467 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00703: val_accuracy did not improve from 0.92857\n",
      "Epoch 704/4000\n",
      " - 0s - loss: 0.0516 - accuracy: 0.9667 - val_loss: 0.2465 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00704: val_accuracy did not improve from 0.92857\n",
      "Epoch 705/4000\n",
      " - 0s - loss: 0.0514 - accuracy: 0.9667 - val_loss: 0.2463 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00705: val_accuracy did not improve from 0.92857\n",
      "Epoch 706/4000\n",
      " - 0s - loss: 0.0512 - accuracy: 0.9667 - val_loss: 0.2460 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00706: val_accuracy did not improve from 0.92857\n",
      "Epoch 707/4000\n",
      " - 0s - loss: 0.0510 - accuracy: 0.9667 - val_loss: 0.2458 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00707: val_accuracy did not improve from 0.92857\n",
      "Epoch 708/4000\n",
      " - 0s - loss: 0.0508 - accuracy: 0.9667 - val_loss: 0.2455 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00708: val_accuracy did not improve from 0.92857\n",
      "Epoch 709/4000\n",
      " - 0s - loss: 0.0506 - accuracy: 0.9667 - val_loss: 0.2453 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00709: val_accuracy did not improve from 0.92857\n",
      "Epoch 710/4000\n",
      " - 0s - loss: 0.0504 - accuracy: 0.9667 - val_loss: 0.2451 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00710: val_accuracy did not improve from 0.92857\n",
      "Epoch 711/4000\n",
      " - 0s - loss: 0.0502 - accuracy: 0.9667 - val_loss: 0.2449 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00711: val_accuracy did not improve from 0.92857\n",
      "Epoch 712/4000\n",
      " - 0s - loss: 0.0500 - accuracy: 0.9667 - val_loss: 0.2447 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00712: val_accuracy did not improve from 0.92857\n",
      "Epoch 713/4000\n",
      " - 0s - loss: 0.0498 - accuracy: 0.9667 - val_loss: 0.2445 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00713: val_accuracy did not improve from 0.92857\n",
      "Epoch 714/4000\n",
      " - 0s - loss: 0.0496 - accuracy: 0.9667 - val_loss: 0.2444 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00714: val_accuracy did not improve from 0.92857\n",
      "Epoch 715/4000\n",
      " - 0s - loss: 0.0494 - accuracy: 0.9667 - val_loss: 0.2442 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00715: val_accuracy did not improve from 0.92857\n",
      "Epoch 716/4000\n",
      " - 0s - loss: 0.0492 - accuracy: 0.9667 - val_loss: 0.2440 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00716: val_accuracy did not improve from 0.92857\n",
      "Epoch 717/4000\n",
      " - 0s - loss: 0.0490 - accuracy: 0.9667 - val_loss: 0.2438 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00717: val_accuracy did not improve from 0.92857\n",
      "Epoch 718/4000\n",
      " - 0s - loss: 0.0489 - accuracy: 0.9667 - val_loss: 0.2436 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00718: val_accuracy did not improve from 0.92857\n",
      "Epoch 719/4000\n",
      " - 0s - loss: 0.0486 - accuracy: 0.9667 - val_loss: 0.2434 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00719: val_accuracy did not improve from 0.92857\n",
      "Epoch 720/4000\n",
      " - 0s - loss: 0.0485 - accuracy: 0.9667 - val_loss: 0.2433 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00720: val_accuracy did not improve from 0.92857\n",
      "Epoch 721/4000\n",
      " - 0s - loss: 0.0483 - accuracy: 0.9667 - val_loss: 0.2431 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00721: val_accuracy did not improve from 0.92857\n",
      "Epoch 722/4000\n",
      " - 0s - loss: 0.0481 - accuracy: 0.9667 - val_loss: 0.2430 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00722: val_accuracy did not improve from 0.92857\n",
      "Epoch 723/4000\n",
      " - 0s - loss: 0.0479 - accuracy: 0.9667 - val_loss: 0.2429 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00723: val_accuracy did not improve from 0.92857\n",
      "Epoch 724/4000\n",
      " - 0s - loss: 0.0477 - accuracy: 0.9667 - val_loss: 0.2427 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00724: val_accuracy did not improve from 0.92857\n",
      "Epoch 725/4000\n",
      " - 0s - loss: 0.0475 - accuracy: 0.9667 - val_loss: 0.2426 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00725: val_accuracy did not improve from 0.92857\n",
      "Epoch 726/4000\n",
      " - 0s - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00726: val_accuracy did not improve from 0.92857\n",
      "Epoch 727/4000\n",
      " - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00727: val_accuracy did not improve from 0.92857\n",
      "Epoch 728/4000\n",
      " - 0s - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00728: val_accuracy did not improve from 0.92857\n",
      "Epoch 729/4000\n",
      " - 0s - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00729: val_accuracy did not improve from 0.92857\n",
      "Epoch 730/4000\n",
      " - 0s - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00730: val_accuracy did not improve from 0.92857\n",
      "Epoch 731/4000\n",
      " - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00731: val_accuracy did not improve from 0.92857\n",
      "Epoch 732/4000\n",
      " - 0s - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00732: val_accuracy did not improve from 0.92857\n",
      "Epoch 733/4000\n",
      " - 0s - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00733: val_accuracy did not improve from 0.92857\n",
      "Epoch 734/4000\n",
      " - 0s - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00734: val_accuracy did not improve from 0.92857\n",
      "Epoch 735/4000\n",
      " - 0s - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00735: val_accuracy did not improve from 0.92857\n",
      "Epoch 736/4000\n",
      " - 0s - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00736: val_accuracy did not improve from 0.92857\n",
      "Epoch 737/4000\n",
      " - 0s - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00737: val_accuracy did not improve from 0.92857\n",
      "Epoch 738/4000\n",
      " - 0s - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00738: val_accuracy did not improve from 0.92857\n",
      "Epoch 739/4000\n",
      " - 0s - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00739: val_accuracy did not improve from 0.92857\n",
      "Epoch 740/4000\n",
      " - 0s - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00740: val_accuracy did not improve from 0.92857\n",
      "Epoch 741/4000\n",
      " - 0s - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00741: val_accuracy did not improve from 0.92857\n",
      "Epoch 742/4000\n",
      " - 0s - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00742: val_accuracy did not improve from 0.92857\n",
      "Epoch 743/4000\n",
      " - 0s - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00743: val_accuracy did not improve from 0.92857\n",
      "Epoch 744/4000\n",
      " - 0s - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00744: val_accuracy did not improve from 0.92857\n",
      "Epoch 745/4000\n",
      " - 0s - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00745: val_accuracy did not improve from 0.92857\n",
      "Epoch 746/4000\n",
      " - 0s - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00746: val_accuracy did not improve from 0.92857\n",
      "Epoch 747/4000\n",
      " - 0s - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00747: val_accuracy did not improve from 0.92857\n",
      "Epoch 748/4000\n",
      " - 0s - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00748: val_accuracy did not improve from 0.92857\n",
      "Epoch 749/4000\n",
      " - 0s - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00749: val_accuracy did not improve from 0.92857\n",
      "Epoch 750/4000\n",
      " - 0s - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00750: val_accuracy did not improve from 0.92857\n",
      "Epoch 751/4000\n",
      " - 0s - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00751: val_accuracy did not improve from 0.92857\n",
      "Epoch 752/4000\n",
      " - 0s - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00752: val_accuracy did not improve from 0.92857\n",
      "Epoch 753/4000\n",
      " - 0s - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00753: val_accuracy did not improve from 0.92857\n",
      "Epoch 754/4000\n",
      " - 0s - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00754: val_accuracy did not improve from 0.92857\n",
      "Epoch 755/4000\n",
      " - 0s - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00755: val_accuracy did not improve from 0.92857\n",
      "Epoch 756/4000\n",
      " - 0s - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00756: val_accuracy did not improve from 0.92857\n",
      "Epoch 757/4000\n",
      " - 0s - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00757: val_accuracy did not improve from 0.92857\n",
      "Epoch 758/4000\n",
      " - 0s - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00758: val_accuracy did not improve from 0.92857\n",
      "Epoch 759/4000\n",
      " - 0s - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00759: val_accuracy did not improve from 0.92857\n",
      "Epoch 760/4000\n",
      " - 0s - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00760: val_accuracy did not improve from 0.92857\n",
      "Epoch 761/4000\n",
      " - 0s - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00761: val_accuracy did not improve from 0.92857\n",
      "Epoch 762/4000\n",
      " - 0s - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00762: val_accuracy did not improve from 0.92857\n",
      "Epoch 763/4000\n",
      " - 0s - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00763: val_accuracy did not improve from 0.92857\n",
      "Epoch 764/4000\n",
      " - 0s - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00764: val_accuracy did not improve from 0.92857\n",
      "Epoch 765/4000\n",
      " - 0s - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00765: val_accuracy did not improve from 0.92857\n",
      "Epoch 766/4000\n",
      " - 0s - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00766: val_accuracy did not improve from 0.92857\n",
      "Epoch 767/4000\n",
      " - 0s - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00767: val_accuracy did not improve from 0.92857\n",
      "Epoch 768/4000\n",
      " - 0s - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00768: val_accuracy did not improve from 0.92857\n",
      "Epoch 769/4000\n",
      " - 0s - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00769: val_accuracy did not improve from 0.92857\n",
      "Epoch 770/4000\n",
      " - 0s - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00770: val_accuracy did not improve from 0.92857\n",
      "Epoch 771/4000\n",
      " - 0s - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00771: val_accuracy did not improve from 0.92857\n",
      "Epoch 772/4000\n",
      " - 0s - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00772: val_accuracy did not improve from 0.92857\n",
      "Epoch 773/4000\n",
      " - 0s - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00773: val_accuracy did not improve from 0.92857\n",
      "Epoch 774/4000\n",
      " - 0s - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00774: val_accuracy did not improve from 0.92857\n",
      "Epoch 775/4000\n",
      " - 0s - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00775: val_accuracy did not improve from 0.92857\n",
      "Epoch 776/4000\n",
      " - 0s - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00776: val_accuracy did not improve from 0.92857\n",
      "Epoch 777/4000\n",
      " - 0s - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00777: val_accuracy did not improve from 0.92857\n",
      "Epoch 778/4000\n",
      " - 0s - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00778: val_accuracy did not improve from 0.92857\n",
      "Epoch 779/4000\n",
      " - 0s - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00779: val_accuracy did not improve from 0.92857\n",
      "Epoch 780/4000\n",
      " - 0s - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00780: val_accuracy did not improve from 0.92857\n",
      "Epoch 781/4000\n",
      " - 0s - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00781: val_accuracy did not improve from 0.92857\n",
      "Epoch 782/4000\n",
      " - 0s - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00782: val_accuracy did not improve from 0.92857\n",
      "Epoch 783/4000\n",
      " - 0s - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00783: val_accuracy did not improve from 0.92857\n",
      "Epoch 784/4000\n",
      " - 0s - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00784: val_accuracy did not improve from 0.92857\n",
      "Epoch 785/4000\n",
      " - 0s - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00785: val_accuracy did not improve from 0.92857\n",
      "Epoch 786/4000\n",
      " - 0s - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00786: val_accuracy did not improve from 0.92857\n",
      "Epoch 787/4000\n",
      " - 0s - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00787: val_accuracy did not improve from 0.92857\n",
      "Epoch 788/4000\n",
      " - 0s - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00788: val_accuracy did not improve from 0.92857\n",
      "Epoch 789/4000\n",
      " - 0s - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00789: val_accuracy did not improve from 0.92857\n",
      "Epoch 790/4000\n",
      " - 0s - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00790: val_accuracy did not improve from 0.92857\n",
      "Epoch 791/4000\n",
      " - 0s - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00791: val_accuracy did not improve from 0.92857\n",
      "Epoch 792/4000\n",
      " - 0s - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00792: val_accuracy did not improve from 0.92857\n",
      "Epoch 793/4000\n",
      " - 0s - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00793: val_accuracy did not improve from 0.92857\n",
      "Epoch 794/4000\n",
      " - 0s - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00794: val_accuracy did not improve from 0.92857\n",
      "Epoch 795/4000\n",
      " - 0s - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00795: val_accuracy did not improve from 0.92857\n",
      "Epoch 796/4000\n",
      " - 0s - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00796: val_accuracy did not improve from 0.92857\n",
      "Epoch 797/4000\n",
      " - 0s - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00797: val_accuracy did not improve from 0.92857\n",
      "Epoch 798/4000\n",
      " - 0s - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00798: val_accuracy did not improve from 0.92857\n",
      "Epoch 799/4000\n",
      " - 0s - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00799: val_accuracy did not improve from 0.92857\n",
      "Epoch 800/4000\n",
      " - 0s - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00800: val_accuracy did not improve from 0.92857\n",
      "Epoch 801/4000\n",
      " - 0s - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00801: val_accuracy did not improve from 0.92857\n",
      "Epoch 802/4000\n",
      " - 0s - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00802: val_accuracy did not improve from 0.92857\n",
      "Epoch 803/4000\n",
      " - 0s - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00803: val_accuracy did not improve from 0.92857\n",
      "Epoch 804/4000\n",
      " - 0s - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00804: val_accuracy did not improve from 0.92857\n",
      "Epoch 805/4000\n",
      " - 0s - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00805: val_accuracy did not improve from 0.92857\n",
      "Epoch 806/4000\n",
      " - 0s - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00806: val_accuracy did not improve from 0.92857\n",
      "Epoch 807/4000\n",
      " - 0s - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00807: val_accuracy did not improve from 0.92857\n",
      "Epoch 808/4000\n",
      " - 0s - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00808: val_accuracy did not improve from 0.92857\n",
      "Epoch 809/4000\n",
      " - 0s - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00809: val_accuracy did not improve from 0.92857\n",
      "Epoch 810/4000\n",
      " - 0s - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00810: val_accuracy did not improve from 0.92857\n",
      "Epoch 811/4000\n",
      " - 0s - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00811: val_accuracy did not improve from 0.92857\n",
      "Epoch 812/4000\n",
      " - 0s - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00812: val_accuracy did not improve from 0.92857\n",
      "Epoch 813/4000\n",
      " - 0s - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00813: val_accuracy did not improve from 0.92857\n",
      "Epoch 814/4000\n",
      " - 0s - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00814: val_accuracy did not improve from 0.92857\n",
      "Epoch 815/4000\n",
      " - 0s - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00815: val_accuracy did not improve from 0.92857\n",
      "Epoch 816/4000\n",
      " - 0s - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00816: val_accuracy did not improve from 0.92857\n",
      "Epoch 817/4000\n",
      " - 0s - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00817: val_accuracy did not improve from 0.92857\n",
      "Epoch 818/4000\n",
      " - 0s - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00818: val_accuracy did not improve from 0.92857\n",
      "Epoch 819/4000\n",
      " - 0s - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00819: val_accuracy did not improve from 0.92857\n",
      "Epoch 820/4000\n",
      " - 0s - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00820: val_accuracy did not improve from 0.92857\n",
      "Epoch 821/4000\n",
      " - 0s - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00821: val_accuracy did not improve from 0.92857\n",
      "Epoch 822/4000\n",
      " - 0s - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00822: val_accuracy did not improve from 0.92857\n",
      "Epoch 823/4000\n",
      " - 0s - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00823: val_accuracy did not improve from 0.92857\n",
      "Epoch 824/4000\n",
      " - 0s - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00824: val_accuracy did not improve from 0.92857\n",
      "Epoch 825/4000\n",
      " - 0s - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00825: val_accuracy did not improve from 0.92857\n",
      "Epoch 826/4000\n",
      " - 0s - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00826: val_accuracy did not improve from 0.92857\n",
      "Epoch 827/4000\n",
      " - 0s - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00827: val_accuracy did not improve from 0.92857\n",
      "Epoch 828/4000\n",
      " - 0s - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00828: val_accuracy did not improve from 0.92857\n",
      "Epoch 829/4000\n",
      " - 0s - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00829: val_accuracy did not improve from 0.92857\n",
      "Epoch 830/4000\n",
      " - 0s - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00830: val_accuracy did not improve from 0.92857\n",
      "Epoch 831/4000\n",
      " - 0s - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00831: val_accuracy did not improve from 0.92857\n",
      "Epoch 832/4000\n",
      " - 0s - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00832: val_accuracy did not improve from 0.92857\n",
      "Epoch 833/4000\n",
      " - 0s - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00833: val_accuracy did not improve from 0.92857\n",
      "Epoch 834/4000\n",
      " - 0s - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00834: val_accuracy did not improve from 0.92857\n",
      "Epoch 835/4000\n",
      " - 0s - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00835: val_accuracy did not improve from 0.92857\n",
      "Epoch 836/4000\n",
      " - 0s - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00836: val_accuracy did not improve from 0.92857\n",
      "Epoch 837/4000\n",
      " - 0s - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00837: val_accuracy did not improve from 0.92857\n",
      "Epoch 838/4000\n",
      " - 0s - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00838: val_accuracy did not improve from 0.92857\n",
      "Epoch 839/4000\n",
      " - 0s - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00839: val_accuracy did not improve from 0.92857\n",
      "Epoch 840/4000\n",
      " - 0s - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00840: val_accuracy did not improve from 0.92857\n",
      "Epoch 841/4000\n",
      " - 0s - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00841: val_accuracy did not improve from 0.92857\n",
      "Epoch 842/4000\n",
      " - 0s - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00842: val_accuracy did not improve from 0.92857\n",
      "Epoch 843/4000\n",
      " - 0s - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00843: val_accuracy did not improve from 0.92857\n",
      "Epoch 844/4000\n",
      " - 0s - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00844: val_accuracy did not improve from 0.92857\n",
      "Epoch 845/4000\n",
      " - 0s - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00845: val_accuracy did not improve from 0.92857\n",
      "Epoch 846/4000\n",
      " - 0s - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00846: val_accuracy did not improve from 0.92857\n",
      "Epoch 847/4000\n",
      " - 0s - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00847: val_accuracy did not improve from 0.92857\n",
      "Epoch 848/4000\n",
      " - 0s - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00848: val_accuracy did not improve from 0.92857\n",
      "Epoch 849/4000\n",
      " - 0s - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00849: val_accuracy did not improve from 0.92857\n",
      "Epoch 850/4000\n",
      " - 0s - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00850: val_accuracy did not improve from 0.92857\n",
      "Epoch 851/4000\n",
      " - 0s - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00851: val_accuracy did not improve from 0.92857\n",
      "Epoch 852/4000\n",
      " - 0s - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00852: val_accuracy did not improve from 0.92857\n",
      "Epoch 853/4000\n",
      " - 0s - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00853: val_accuracy did not improve from 0.92857\n",
      "Epoch 854/4000\n",
      " - 0s - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00854: val_accuracy did not improve from 0.92857\n",
      "Epoch 855/4000\n",
      " - 0s - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00855: val_accuracy did not improve from 0.92857\n",
      "Epoch 856/4000\n",
      " - 0s - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00856: val_accuracy did not improve from 0.92857\n",
      "Epoch 857/4000\n",
      " - 0s - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00857: val_accuracy did not improve from 0.92857\n",
      "Epoch 858/4000\n",
      " - 0s - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00858: val_accuracy did not improve from 0.92857\n",
      "Epoch 859/4000\n",
      " - 0s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00859: val_accuracy did not improve from 0.92857\n",
      "Epoch 860/4000\n",
      " - 0s - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00860: val_accuracy did not improve from 0.92857\n",
      "Epoch 861/4000\n",
      " - 0s - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00861: val_accuracy did not improve from 0.92857\n",
      "Epoch 862/4000\n",
      " - 0s - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00862: val_accuracy did not improve from 0.92857\n",
      "Epoch 863/4000\n",
      " - 0s - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00863: val_accuracy did not improve from 0.92857\n",
      "Epoch 864/4000\n",
      " - 0s - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00864: val_accuracy did not improve from 0.92857\n",
      "Epoch 865/4000\n",
      " - 0s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00865: val_accuracy did not improve from 0.92857\n",
      "Epoch 866/4000\n",
      " - 0s - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00866: val_accuracy did not improve from 0.92857\n",
      "Epoch 867/4000\n",
      " - 0s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00867: val_accuracy did not improve from 0.92857\n",
      "Epoch 868/4000\n",
      " - 0s - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00868: val_accuracy did not improve from 0.92857\n",
      "Epoch 869/4000\n",
      " - 0s - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00869: val_accuracy did not improve from 0.92857\n",
      "Epoch 870/4000\n",
      " - 0s - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00870: val_accuracy did not improve from 0.92857\n",
      "Epoch 871/4000\n",
      " - 0s - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00871: val_accuracy did not improve from 0.92857\n",
      "Epoch 872/4000\n",
      " - 0s - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00872: val_accuracy did not improve from 0.92857\n",
      "Epoch 873/4000\n",
      " - 0s - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00873: val_accuracy did not improve from 0.92857\n",
      "Epoch 874/4000\n",
      " - 0s - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00874: val_accuracy improved from 0.92857 to 0.94286, saving model to best_model.h5\n",
      "Epoch 875/4000\n",
      " - 0s - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00875: val_accuracy did not improve from 0.94286\n",
      "Epoch 876/4000\n",
      " - 0s - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00876: val_accuracy did not improve from 0.94286\n",
      "Epoch 877/4000\n",
      " - 0s - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00877: val_accuracy did not improve from 0.94286\n",
      "Epoch 878/4000\n",
      " - 0s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00878: val_accuracy did not improve from 0.94286\n",
      "Epoch 879/4000\n",
      " - 0s - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00879: val_accuracy did not improve from 0.94286\n",
      "Epoch 880/4000\n",
      " - 0s - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00880: val_accuracy did not improve from 0.94286\n",
      "Epoch 881/4000\n",
      " - 0s - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00881: val_accuracy did not improve from 0.94286\n",
      "Epoch 882/4000\n",
      " - 0s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00882: val_accuracy did not improve from 0.94286\n",
      "Epoch 883/4000\n",
      " - 0s - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00883: val_accuracy did not improve from 0.94286\n",
      "Epoch 884/4000\n",
      " - 0s - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00884: val_accuracy did not improve from 0.94286\n",
      "Epoch 885/4000\n",
      " - 0s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00885: val_accuracy did not improve from 0.94286\n",
      "Epoch 886/4000\n",
      " - 0s - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00886: val_accuracy did not improve from 0.94286\n",
      "Epoch 887/4000\n",
      " - 0s - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00887: val_accuracy did not improve from 0.94286\n",
      "Epoch 888/4000\n",
      " - 0s - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00888: val_accuracy did not improve from 0.94286\n",
      "Epoch 889/4000\n",
      " - 0s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00889: val_accuracy did not improve from 0.94286\n",
      "Epoch 890/4000\n",
      " - 0s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00890: val_accuracy did not improve from 0.94286\n",
      "Epoch 891/4000\n",
      " - 0s - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00891: val_accuracy did not improve from 0.94286\n",
      "Epoch 892/4000\n",
      " - 0s - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00892: val_accuracy did not improve from 0.94286\n",
      "Epoch 893/4000\n",
      " - 0s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00893: val_accuracy did not improve from 0.94286\n",
      "Epoch 894/4000\n",
      " - 0s - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00894: val_accuracy did not improve from 0.94286\n",
      "Epoch 895/4000\n",
      " - 0s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00895: val_accuracy did not improve from 0.94286\n",
      "Epoch 896/4000\n",
      " - 0s - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00896: val_accuracy did not improve from 0.94286\n",
      "Epoch 897/4000\n",
      " - 0s - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00897: val_accuracy did not improve from 0.94286\n",
      "Epoch 898/4000\n",
      " - 0s - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00898: val_accuracy did not improve from 0.94286\n",
      "Epoch 899/4000\n",
      " - 0s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00899: val_accuracy did not improve from 0.94286\n",
      "Epoch 900/4000\n",
      " - 0s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00900: val_accuracy did not improve from 0.94286\n",
      "Epoch 901/4000\n",
      " - 0s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00901: val_accuracy did not improve from 0.94286\n",
      "Epoch 902/4000\n",
      " - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00902: val_accuracy did not improve from 0.94286\n",
      "Epoch 903/4000\n",
      " - 0s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00903: val_accuracy did not improve from 0.94286\n",
      "Epoch 904/4000\n",
      " - 0s - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00904: val_accuracy did not improve from 0.94286\n",
      "Epoch 905/4000\n",
      " - 0s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00905: val_accuracy did not improve from 0.94286\n",
      "Epoch 906/4000\n",
      " - 0s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00906: val_accuracy did not improve from 0.94286\n",
      "Epoch 907/4000\n",
      " - 0s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00907: val_accuracy did not improve from 0.94286\n",
      "Epoch 908/4000\n",
      " - 0s - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00908: val_accuracy did not improve from 0.94286\n",
      "Epoch 909/4000\n",
      " - 0s - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00909: val_accuracy did not improve from 0.94286\n",
      "Epoch 910/4000\n",
      " - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00910: val_accuracy did not improve from 0.94286\n",
      "Epoch 911/4000\n",
      " - 0s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00911: val_accuracy did not improve from 0.94286\n",
      "Epoch 912/4000\n",
      " - 0s - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00912: val_accuracy did not improve from 0.94286\n",
      "Epoch 913/4000\n",
      " - 0s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00913: val_accuracy did not improve from 0.94286\n",
      "Epoch 914/4000\n",
      " - 0s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00914: val_accuracy did not improve from 0.94286\n",
      "Epoch 915/4000\n",
      " - 0s - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00915: val_accuracy did not improve from 0.94286\n",
      "Epoch 916/4000\n",
      " - 0s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00916: val_accuracy did not improve from 0.94286\n",
      "Epoch 917/4000\n",
      " - 0s - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00917: val_accuracy did not improve from 0.94286\n",
      "Epoch 918/4000\n",
      " - 0s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00918: val_accuracy did not improve from 0.94286\n",
      "Epoch 919/4000\n",
      " - 0s - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00919: val_accuracy did not improve from 0.94286\n",
      "Epoch 920/4000\n",
      " - 0s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00920: val_accuracy did not improve from 0.94286\n",
      "Epoch 921/4000\n",
      " - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00921: val_accuracy did not improve from 0.94286\n",
      "Epoch 922/4000\n",
      " - 0s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00922: val_accuracy did not improve from 0.94286\n",
      "Epoch 923/4000\n",
      " - 0s - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00923: val_accuracy did not improve from 0.94286\n",
      "Epoch 924/4000\n",
      " - 0s - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00924: val_accuracy did not improve from 0.94286\n",
      "Epoch 925/4000\n",
      " - 0s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00925: val_accuracy did not improve from 0.94286\n",
      "Epoch 926/4000\n",
      " - 0s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00926: val_accuracy did not improve from 0.94286\n",
      "Epoch 927/4000\n",
      " - 0s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00927: val_accuracy did not improve from 0.94286\n",
      "Epoch 928/4000\n",
      " - 0s - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00928: val_accuracy did not improve from 0.94286\n",
      "Epoch 929/4000\n",
      " - 0s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00929: val_accuracy did not improve from 0.94286\n",
      "Epoch 930/4000\n",
      " - 0s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00930: val_accuracy did not improve from 0.94286\n",
      "Epoch 931/4000\n",
      " - 0s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00931: val_accuracy did not improve from 0.94286\n",
      "Epoch 932/4000\n",
      " - 0s - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00932: val_accuracy did not improve from 0.94286\n",
      "Epoch 933/4000\n",
      " - 0s - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00933: val_accuracy did not improve from 0.94286\n",
      "Epoch 934/4000\n",
      " - 0s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00934: val_accuracy did not improve from 0.94286\n",
      "Epoch 935/4000\n",
      " - 0s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00935: val_accuracy did not improve from 0.94286\n",
      "Epoch 936/4000\n",
      " - 0s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00936: val_accuracy did not improve from 0.94286\n",
      "Epoch 937/4000\n",
      " - 0s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00937: val_accuracy did not improve from 0.94286\n",
      "Epoch 938/4000\n",
      " - 0s - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00938: val_accuracy did not improve from 0.94286\n",
      "Epoch 939/4000\n",
      " - 0s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00939: val_accuracy did not improve from 0.94286\n",
      "Epoch 940/4000\n",
      " - 0s - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00940: val_accuracy did not improve from 0.94286\n",
      "Epoch 941/4000\n",
      " - 0s - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00941: val_accuracy did not improve from 0.94286\n",
      "Epoch 942/4000\n",
      " - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00942: val_accuracy did not improve from 0.94286\n",
      "Epoch 943/4000\n",
      " - 0s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00943: val_accuracy did not improve from 0.94286\n",
      "Epoch 944/4000\n",
      " - 0s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00944: val_accuracy did not improve from 0.94286\n",
      "Epoch 945/4000\n",
      " - 0s - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00945: val_accuracy did not improve from 0.94286\n",
      "Epoch 946/4000\n",
      " - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00946: val_accuracy did not improve from 0.94286\n",
      "Epoch 947/4000\n",
      " - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00947: val_accuracy did not improve from 0.94286\n",
      "Epoch 948/4000\n",
      " - 0s - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00948: val_accuracy did not improve from 0.94286\n",
      "Epoch 949/4000\n",
      " - 0s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00949: val_accuracy did not improve from 0.94286\n",
      "Epoch 950/4000\n",
      " - 0s - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00950: val_accuracy did not improve from 0.94286\n",
      "Epoch 951/4000\n",
      " - 0s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00951: val_accuracy did not improve from 0.94286\n",
      "Epoch 952/4000\n",
      " - 0s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00952: val_accuracy did not improve from 0.94286\n",
      "Epoch 953/4000\n",
      " - 0s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00953: val_accuracy did not improve from 0.94286\n",
      "Epoch 954/4000\n",
      " - 0s - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00954: val_accuracy did not improve from 0.94286\n",
      "Epoch 955/4000\n",
      " - 0s - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00955: val_accuracy did not improve from 0.94286\n",
      "Epoch 956/4000\n",
      " - 0s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00956: val_accuracy did not improve from 0.94286\n",
      "Epoch 957/4000\n",
      " - 0s - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00957: val_accuracy did not improve from 0.94286\n",
      "Epoch 958/4000\n",
      " - 0s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00958: val_accuracy did not improve from 0.94286\n",
      "Epoch 959/4000\n",
      " - 0s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00959: val_accuracy did not improve from 0.94286\n",
      "Epoch 960/4000\n",
      " - 0s - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00960: val_accuracy did not improve from 0.94286\n",
      "Epoch 961/4000\n",
      " - 0s - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00961: val_accuracy did not improve from 0.94286\n",
      "Epoch 962/4000\n",
      " - 0s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00962: val_accuracy did not improve from 0.94286\n",
      "Epoch 963/4000\n",
      " - 0s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00963: val_accuracy did not improve from 0.94286\n",
      "Epoch 964/4000\n",
      " - 0s - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00964: val_accuracy did not improve from 0.94286\n",
      "Epoch 965/4000\n",
      " - 0s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00965: val_accuracy did not improve from 0.94286\n",
      "Epoch 966/4000\n",
      " - 0s - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00966: val_accuracy did not improve from 0.94286\n",
      "Epoch 967/4000\n",
      " - 0s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00967: val_accuracy did not improve from 0.94286\n",
      "Epoch 968/4000\n",
      " - 0s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00968: val_accuracy did not improve from 0.94286\n",
      "Epoch 969/4000\n",
      " - 0s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00969: val_accuracy did not improve from 0.94286\n",
      "Epoch 970/4000\n",
      " - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00970: val_accuracy did not improve from 0.94286\n",
      "Epoch 971/4000\n",
      " - 0s - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00971: val_accuracy did not improve from 0.94286\n",
      "Epoch 972/4000\n",
      " - 0s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00972: val_accuracy did not improve from 0.94286\n",
      "Epoch 973/4000\n",
      " - 0s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00973: val_accuracy did not improve from 0.94286\n",
      "Epoch 974/4000\n",
      " - 0s - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00974: val_accuracy did not improve from 0.94286\n",
      "Epoch 975/4000\n",
      " - 0s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00975: val_accuracy did not improve from 0.94286\n",
      "Epoch 976/4000\n",
      " - 0s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00976: val_accuracy did not improve from 0.94286\n",
      "Epoch 977/4000\n",
      " - 0s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00977: val_accuracy did not improve from 0.94286\n",
      "Epoch 978/4000\n",
      " - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00978: val_accuracy did not improve from 0.94286\n",
      "Epoch 979/4000\n",
      " - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00979: val_accuracy did not improve from 0.94286\n",
      "Epoch 980/4000\n",
      " - 0s - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00980: val_accuracy did not improve from 0.94286\n",
      "Epoch 981/4000\n",
      " - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00981: val_accuracy did not improve from 0.94286\n",
      "Epoch 982/4000\n",
      " - 0s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00982: val_accuracy did not improve from 0.94286\n",
      "Epoch 983/4000\n",
      " - 0s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00983: val_accuracy did not improve from 0.94286\n",
      "Epoch 984/4000\n",
      " - 0s - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00984: val_accuracy did not improve from 0.94286\n",
      "Epoch 985/4000\n",
      " - 0s - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00985: val_accuracy did not improve from 0.94286\n",
      "Epoch 986/4000\n",
      " - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00986: val_accuracy did not improve from 0.94286\n",
      "Epoch 987/4000\n",
      " - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00987: val_accuracy did not improve from 0.94286\n",
      "Epoch 988/4000\n",
      " - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00988: val_accuracy did not improve from 0.94286\n",
      "Epoch 989/4000\n",
      " - 0s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00989: val_accuracy did not improve from 0.94286\n",
      "Epoch 990/4000\n",
      " - 0s - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00990: val_accuracy did not improve from 0.94286\n",
      "Epoch 991/4000\n",
      " - 0s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00991: val_accuracy did not improve from 0.94286\n",
      "Epoch 992/4000\n",
      " - 0s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00992: val_accuracy did not improve from 0.94286\n",
      "Epoch 993/4000\n",
      " - 0s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00993: val_accuracy did not improve from 0.94286\n",
      "Epoch 994/4000\n",
      " - 0s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00994: val_accuracy did not improve from 0.94286\n",
      "Epoch 995/4000\n",
      " - 0s - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00995: val_accuracy did not improve from 0.94286\n",
      "Epoch 996/4000\n",
      " - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00996: val_accuracy did not improve from 0.94286\n",
      "Epoch 997/4000\n",
      " - 0s - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00997: val_accuracy did not improve from 0.94286\n",
      "Epoch 998/4000\n",
      " - 0s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00998: val_accuracy did not improve from 0.94286\n",
      "Epoch 999/4000\n",
      " - 0s - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00999: val_accuracy did not improve from 0.94286\n",
      "Epoch 1000/4000\n",
      " - 0s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01000: val_accuracy did not improve from 0.94286\n",
      "Epoch 1001/4000\n",
      " - 0s - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01001: val_accuracy did not improve from 0.94286\n",
      "Epoch 1002/4000\n",
      " - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01002: val_accuracy did not improve from 0.94286\n",
      "Epoch 1003/4000\n",
      " - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01003: val_accuracy did not improve from 0.94286\n",
      "Epoch 1004/4000\n",
      " - 0s - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01004: val_accuracy did not improve from 0.94286\n",
      "Epoch 1005/4000\n",
      " - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01005: val_accuracy did not improve from 0.94286\n",
      "Epoch 1006/4000\n",
      " - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01006: val_accuracy did not improve from 0.94286\n",
      "Epoch 1007/4000\n",
      " - 0s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01007: val_accuracy did not improve from 0.94286\n",
      "Epoch 1008/4000\n",
      " - 0s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01008: val_accuracy did not improve from 0.94286\n",
      "Epoch 1009/4000\n",
      " - 0s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01009: val_accuracy did not improve from 0.94286\n",
      "Epoch 1010/4000\n",
      " - 0s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01010: val_accuracy did not improve from 0.94286\n",
      "Epoch 1011/4000\n",
      " - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01011: val_accuracy did not improve from 0.94286\n",
      "Epoch 1012/4000\n",
      " - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01012: val_accuracy did not improve from 0.94286\n",
      "Epoch 1013/4000\n",
      " - 0s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01013: val_accuracy did not improve from 0.94286\n",
      "Epoch 1014/4000\n",
      " - 0s - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01014: val_accuracy did not improve from 0.94286\n",
      "Epoch 1015/4000\n",
      " - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01015: val_accuracy did not improve from 0.94286\n",
      "Epoch 1016/4000\n",
      " - 0s - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01016: val_accuracy did not improve from 0.94286\n",
      "Epoch 1017/4000\n",
      " - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01017: val_accuracy did not improve from 0.94286\n",
      "Epoch 1018/4000\n",
      " - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01018: val_accuracy did not improve from 0.94286\n",
      "Epoch 1019/4000\n",
      " - 0s - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01019: val_accuracy did not improve from 0.94286\n",
      "Epoch 1020/4000\n",
      " - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01020: val_accuracy did not improve from 0.94286\n",
      "Epoch 1021/4000\n",
      " - 0s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 01021: val_accuracy did not improve from 0.94286\n",
      "Epoch 01021: early stopping\n",
      "Train: 1.000, Test: 0.943\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=2, callbacks=[es, mc])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e05ac7d120f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdot_img_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model_1.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdot_img_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "dot_img_file = 'model_1.png'\n",
    "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
